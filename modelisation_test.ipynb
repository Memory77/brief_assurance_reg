{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age     sex     bmi  children smoker     region      charges\n",
      "0   19  female  27.900         0    yes  southwest  16884.92400\n",
      "1   18    male  33.770         1     no  southeast   1725.55230\n",
      "2   28    male  33.000         3     no  southeast   4449.46200\n",
      "3   33    male  22.705         0     no  northwest  21984.47061\n",
      "4   32    male  28.880         0     no  northwest   3866.85520 (1337, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('dataset2.csv')\n",
    "\n",
    "print(df.head(), df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verif des dimensions X et Y\n",
      "      X (dataset sans la variable cible): (1337, 6)\n",
      "      Y (la variable cible) : (1337, 1)\n",
      " verif du split 80 20 \n",
      "80% du dataset : X train -> (1136, 6), Y train -> (1136, 1)\n",
      "20% du dataset : X test -> (201, 6), Y test -> (201, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet, LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, FunctionTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "\n",
    "# separation des features et de la variable cible\n",
    "X = df.drop('charges', axis=1)\n",
    "y = df[['charges']]\n",
    "print(f'''verif des dimensions X et Y\n",
    "      X (dataset sans la variable cible): {X.shape}\n",
    "      Y (la variable cible) : {y.shape}''')\n",
    "\n",
    "\n",
    "# division du dataset en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, train_size=0.85, random_state=42, stratify=X['smoker'])\n",
    "print(f''' verif du split 80 20 \n",
    "80% du dataset : X train -> {X_train.shape}, Y train -> {y_train.shape}\n",
    "20% du dataset : X test -> {X_test.shape}, Y test -> {y_test.shape}''')\n",
    "\n",
    "def log_transform(x):\n",
    "    return np.log(x + 1)\n",
    "\n",
    "log_transformer = FunctionTransformer(log_transform)\n",
    "\n",
    "preprocessor_num = Pipeline(steps=[\n",
    "    ('log', FunctionTransformer(log_transform)),\n",
    "])\n",
    "\n",
    "preprocessor_cat = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', preprocessor_num, ['age', 'bmi', 'children']),\n",
    "        ('cat', preprocessor_cat, ['region', 'sex', 'smoker'])\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error du modèle dummy: 145320521.96584958\n",
      "Coefficient de determination R² du modèle dummy: -0.0027928862543942223\n",
      "Root Mean Squared Error (RMSE) du modèle dummy: 12054.89618229247\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# création du pipeline dummy\n",
    "pipeline_dummy = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', DummyRegressor(strategy='mean'))])\n",
    "\n",
    "\n",
    "# eviter data leakage -> entraîner le pipeline sur les données d'entraînement puis predire\n",
    "# sur l'ensemble de test avec le meme pipeline\n",
    "pipeline_dummy.fit(X_train, y_train)\n",
    "#puis predire y sur l'ensemble de test avec le meme pipeline\n",
    "y_pred = pipeline_dummy.predict(X_test)\n",
    "#print(y_pred_dummy)\n",
    "\n",
    "#test avec les differentes métriques pour le modele dummy : \n",
    "#comparaison du y prédit avec le y de test\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error du modèle dummy: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Coefficient de determination R² du modèle dummy: {r2}')\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE) du modèle dummy: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3141.13260706]\n",
      " [35296.49048949]\n",
      " [ 6501.13260706]\n",
      " [40210.49048949]\n",
      " [29208.49048949]\n",
      " [ 7521.13260706]\n",
      " [ 3380.13260706]\n",
      " [ 4859.13260706]\n",
      " [ 2841.13260706]\n",
      " [39118.49048949]\n",
      " [10049.13260706]\n",
      " [12701.13260706]\n",
      " [ 3583.13260706]\n",
      " [12675.13260706]\n",
      " [ 3115.13260706]\n",
      " [ 3027.13260706]\n",
      " [ 2032.63260706]\n",
      " [ 6425.13260706]\n",
      " [ 5656.13260706]\n",
      " [19352.49048949]\n",
      " [14210.13260706]\n",
      " [10501.13260706]\n",
      " [13602.13260706]\n",
      " [13340.13260706]\n",
      " [ 6362.38260706]\n",
      " [ 3507.13260706]\n",
      " [13137.13260706]\n",
      " [11945.13260706]\n",
      " [ 3710.13260706]\n",
      " [ 3160.13260706]\n",
      " [ 4599.13260706]\n",
      " [12351.13260706]\n",
      " [10719.13260706]\n",
      " [21168.49048949]\n",
      " [30236.49048949]\n",
      " [49050.49048949]\n",
      " [ 5393.13260706]\n",
      " [12206.13260706]\n",
      " [17467.13260706]\n",
      " [11357.13260706]\n",
      " [ 5807.13260706]\n",
      " [ 5905.13260706]\n",
      " [28440.49048949]\n",
      " [13360.49048949]\n",
      " [30794.49048949]\n",
      " [ 3363.13260706]\n",
      " [11245.13260706]\n",
      " [12194.13260706]\n",
      " [41524.49048949]\n",
      " [11755.13260706]\n",
      " [ 6825.13260706]\n",
      " [41960.49048949]\n",
      " [15441.13260706]\n",
      " [13853.13260706]\n",
      " [ 2533.13260706]\n",
      " [15467.13260706]\n",
      " [ 7451.13260706]\n",
      " [ 9939.13260706]\n",
      " [ 9547.13260706]\n",
      " [ 5720.63260706]\n",
      " [ 3593.13260706]\n",
      " [41152.49048949]\n",
      " [11716.63260706]\n",
      " [10581.13260706]\n",
      " [15749.13260706]\n",
      " [ 9556.49048949]\n",
      " [ 3551.13260706]\n",
      " [12535.13260706]\n",
      " [ 6427.13260706]\n",
      " [ 5225.13260706]\n",
      " [ 6633.13260706]\n",
      " [ 9267.13260706]\n",
      " [32064.49048949]\n",
      " [ 8775.13260706]\n",
      " [40932.49048949]\n",
      " [ 6922.13260706]\n",
      " [ 5723.13260706]\n",
      " [13077.13260706]\n",
      " [12810.13260706]\n",
      " [31848.49048949]\n",
      " [ 2887.13260706]\n",
      " [ 3468.13260706]\n",
      " [10697.13260706]\n",
      " [26704.49048949]\n",
      " [11115.13260706]\n",
      " [36494.49048949]\n",
      " [10089.13260706]\n",
      " [ 4687.13260706]\n",
      " [12848.13260706]\n",
      " [12962.13260706]\n",
      " [ 9468.13260706]\n",
      " [28768.49048949]\n",
      " [13061.13260706]\n",
      " [10111.13260706]\n",
      " [ 4425.13260706]\n",
      " [ 3064.13260706]\n",
      " [ 5353.13260706]\n",
      " [ 5662.63260706]\n",
      " [ 8798.63260706]\n",
      " [11095.13260706]\n",
      " [ 5453.13260706]\n",
      " [ 6463.13260706]\n",
      " [ 3769.13260706]\n",
      " [ 5909.63260706]\n",
      " [ 2647.13260706]\n",
      " [34654.49048949]\n",
      " [ 5285.63260706]\n",
      " [12503.13260706]\n",
      " [ 4379.13260706]\n",
      " [11095.13260706]\n",
      " [14313.13260706]\n",
      " [ 5589.13260706]\n",
      " [10977.13260706]\n",
      " [10497.13260706]\n",
      " [11621.63260706]\n",
      " [ 9889.13260706]\n",
      " [ 7603.13260706]\n",
      " [ 5727.13260706]\n",
      " [13349.13260706]\n",
      " [16400.49048949]\n",
      " [14766.13260706]\n",
      " [11489.63260706]\n",
      " [ 3307.13260706]\n",
      " [24670.49048949]\n",
      " [28176.49048949]\n",
      " [12117.13260706]\n",
      " [10685.13260706]\n",
      " [ 6763.13260706]\n",
      " [ 9182.13260706]\n",
      " [38880.49048949]\n",
      " [ 7923.13260706]\n",
      " [ 5341.13260706]\n",
      " [ 3689.13260706]\n",
      " [ 3266.13260706]\n",
      " [ 3800.13260706]\n",
      " [ 8793.13260706]\n",
      " [14749.13260706]\n",
      " [ 5927.13260706]\n",
      " [11013.63260706]\n",
      " [ 5655.13260706]\n",
      " [ 6145.13260706]\n",
      " [13209.13260706]\n",
      " [ 8817.13260706]\n",
      " [10633.13260706]\n",
      " [35540.49048949]\n",
      " [11290.13260706]\n",
      " [ 4709.13260706]\n",
      " [ 1958.13260706]\n",
      " [11065.13260706]\n",
      " [ 3974.13260706]\n",
      " [48760.49048949]\n",
      " [12233.13260706]\n",
      " [ 9748.13260706]\n",
      " [ 7888.63260706]\n",
      " [10641.13260706]\n",
      " [31560.49048949]\n",
      " [27640.49048949]\n",
      " [ 7795.13260706]\n",
      " [12003.13260706]\n",
      " [51452.49048949]\n",
      " [21096.49048949]\n",
      " [ 3905.13260706]\n",
      " [ 8543.13260706]\n",
      " [47456.49048949]\n",
      " [ 7855.13260706]\n",
      " [28458.49048949]\n",
      " [ 3515.13260706]\n",
      " [54032.49048949]\n",
      " [ 5239.13260706]\n",
      " [36236.49048949]\n",
      " [ 3576.13260706]\n",
      " [11352.13260706]\n",
      " [11742.13260706]\n",
      " [ 4901.13260706]\n",
      " [14351.13260706]\n",
      " [ 6361.13260706]\n",
      " [ 7047.13260706]\n",
      " [ 9033.13260706]\n",
      " [ 9154.13260706]\n",
      " [20984.49048949]\n",
      " [10887.13260706]\n",
      " [ 5911.13260706]\n",
      " [ 9627.13260706]\n",
      " [15713.13260706]\n",
      " [12700.13260706]\n",
      " [ 2353.13260706]\n",
      " [15601.13260706]\n",
      " [11409.13260706]\n",
      " [16216.49048949]\n",
      " [ 7403.13260706]\n",
      " [10410.63260706]\n",
      " [ 4997.13260706]\n",
      " [35192.49048949]\n",
      " [11813.13260706]\n",
      " [10125.13260706]\n",
      " [ 3921.13260706]\n",
      " [35908.49048949]\n",
      " [12070.13260706]\n",
      " [ 5241.13260706]\n",
      " [45612.49048949]\n",
      " [ 6452.13260706]]\n",
      "Mean Squared Error du modèle linear regression: 13887527.047440736\n",
      "Coefficient de determination R² du modèle linear regression: 0.9041682954172725\n",
      "Root Mean Squared Error (RMSE) du modèle linear regression: 3726.597247817469\n"
     ]
    }
   ],
   "source": [
    "# Modele de regression lineaire\n",
    "\n",
    "# création du pipeline de prétraitement et du modèle linear regression\n",
    "pipeline_lr = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "                            ('scaler', StandardScaler()),\n",
    "                           ('regression', LinearRegression())])\n",
    "\n",
    "\n",
    "# entraîner le pipeline sur les données d'entraînement \n",
    "pipeline_lr.fit(X_train, y_train)\n",
    "#puis predire y sur l'ensemble de test avec le meme pipeline\n",
    "y_pred = pipeline_lr.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "#test des les differents metriques sur modele linear regression\n",
    "#comparaison du y prédit avec le y de test\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error du modèle linear regression: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Coefficient de determination R² du modèle linear regression: {r2}')\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE) du modèle linear regression: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13279.121486655948\n",
      "3726.597247817469\n"
     ]
    }
   ],
   "source": [
    "# Calculez le RMSE (la racine carrée du MSE) pour obtenir une idée de l'erreur en termes des unités d'origine de vos données. \n",
    "# Comparez le RMSE à la moyenne des 'charges' (df['charges'].mean()) pour évaluer l'erreur relative.\n",
    "\n",
    "# RMSE plus élevé que la moyenne : le modèle a du mal à capturer la variation et les tendances dans les données. \n",
    "# Il prédit généralement des valeurs qui sont relativement éloignées des valeurs réelles.\n",
    "\n",
    "# Erreur systématique :  le modèle a tendance à sous-estimer ou surestimer systématiquement les valeurs cibles.\n",
    "\n",
    "# Modèle insuffisamment performant : Un RMSE élevé peut également indiquer que le modèle que vous utilisez n'est pas suffisamment complexe \n",
    "# pour capturer les relations présentes dans les données. Cela peut signifier que le modèle ne tient pas compte de toutes les caractéristiques\n",
    "# pertinentes ou que la stratégie de prédiction choisie (comme la moyenne) n'est pas adaptée aux données.\n",
    "\n",
    "# En général, un bon modèle de régression devrait avoir un RMSE inférieur à la moyenne de la variable cible, \n",
    "# car cela indiquerait que le modèle est capable de faire des prédictions qui se rapprochent des valeurs réelles en moyenne. \n",
    "# L'objectif est de minimiser le RMSE pour obtenir des prédictions précises.\n",
    "\n",
    "print(df['charges'].mean())\n",
    "print(rmse)\n",
    "\n",
    "#donc on en résume que le modele dummy est tres mauvais, et c'est normal car le modele dummy \n",
    "#en général, le modèle dummy est un modèle très simple et naïf qui est utilisé comme baseline \n",
    "#pour évaluer la performance d'autres modèles plus sophistiqués."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donc on en résume que le modele dummy est tres mauvais, et c'est normal car le modele dummy <br>\n",
    "est un modèle très simple et naïf qui est utilisé comme baseline pour évaluer la performance d'autres modèles plus sophistiqués"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+10, tolerance: 1.315e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.130e+10, tolerance: 1.298e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.146e+10, tolerance: 1.397e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.128e+10, tolerance: 1.381e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.687e+09, tolerance: 1.271e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.238e+09, tolerance: 1.315e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e+10, tolerance: 1.298e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.001e+10, tolerance: 1.397e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.013e+10, tolerance: 1.381e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.675e+09, tolerance: 1.271e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.544e+09, tolerance: 1.315e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.928e+09, tolerance: 1.298e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.846e+09, tolerance: 1.397e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.765e+09, tolerance: 1.381e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.180e+09, tolerance: 1.271e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error du modèle lasso: 13672195.929661542\n",
      "Coefficient de determination R² du modèle lasso: 0.9056542005749\n",
      "Root Mean Squared Error (RMSE) du modèle lasso: 3697.5932617936146 \n",
      " rappel moyenne charge : 13279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.213e+10, tolerance: 1.667e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# AVEC LE Modele de regression LASSO\n",
    "\n",
    "# création du pipeline de prétraitement et du modèle LASSO\n",
    "pipeline_lasso = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                            ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "                            ('scaler', StandardScaler()),\n",
    "                           ('regression', Lasso())])\n",
    "\n",
    "#test de différents hyperparam d'alpha pour le lasso\n",
    "param_grid_lasso = {\n",
    "    'regression__alpha': [0.1, 1, 10, 100]  \n",
    "}\n",
    "\n",
    "### grid search\n",
    "grid_lasso = GridSearchCV(pipeline_lasso, param_grid_lasso, cv=5)\n",
    "\n",
    "\n",
    "# eviter data leakage -> entraîner le pipeline sur les données d'entraînement \n",
    "grid_lasso.fit(X_train, y_train)\n",
    "#puis predire y sur l'ensemble de test avec le meme pipeline\n",
    "y_pred = grid_lasso.predict(X_test)\n",
    "# print(y_pred)\n",
    "#test des les differents metriques sur modele lasso\n",
    "#comparaison du y prédit avec le y de test\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error du modèle lasso: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Coefficient de determination R² du modèle lasso: {r2}')\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE) du modèle lasso: {rmse} \\n rappel moyenne charge : 13279')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient de determination R² du modèle ridge: 0.9047634612377543\n",
      "Root Mean Squared Error (RMSE) du modèle ridge: 3715.0071498164157 \n",
      " rappel moyenne charge : 13279\n"
     ]
    }
   ],
   "source": [
    "# Modele de regression RIDGE\n",
    "\n",
    "# création du pipeline de prétraitement et du modèle RIDGE\n",
    "pipeline_ridge = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                            ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "                            ('scaler', StandardScaler()),\n",
    "                           ('regression', Ridge())])\n",
    "\n",
    "\n",
    "#test de différents hyperparam d'alpha pour le lasso\n",
    "param_grid_ridge = {\n",
    "    'regression__alpha': [0.01, 0.1, 1, 10, 100]  \n",
    "}\n",
    "\n",
    "### grid search\n",
    "grid_ridge = GridSearchCV(pipeline_ridge, param_grid_ridge, cv=5)\n",
    "\n",
    "\n",
    "# eviter data leakage -> entraîner le pipeline sur les données d'entraînement \n",
    "grid_ridge.fit(X_train, y_train)\n",
    "#puis predire y sur l'ensemble de test avec le meme pipeline\n",
    "y_pred = grid_ridge.predict(X_test)\n",
    "# print(y_pred)\n",
    "#test des les differents metriques sur modele lasso\n",
    "#comparaison du y prédit avec le y de test\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Coefficient de determination R² du modèle ridge: {r2}')\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE) du modèle ridge: {rmse} \\n rappel moyenne charge : 13279')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
