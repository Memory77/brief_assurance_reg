{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  sex     bmi  children  smoker     region      charges  \\\n",
      "0   19    1  27.900         0       1  southwest  16884.92400   \n",
      "1   18    0  33.770         1       0  southeast   1725.55230   \n",
      "2   28    0  33.000         3       0  southeast   4449.46200   \n",
      "3   33    0  22.705         0       0  northwest  21984.47061   \n",
      "4   32    0  28.880         0       0  northwest   3866.85520   \n",
      "\n",
      "   bmi_smoker_interaction  \n",
      "0                    27.9  \n",
      "1                     0.0  \n",
      "2                     0.0  \n",
      "3                     0.0  \n",
      "4                     0.0   (1337, 8)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('dataset3.csv')\n",
    "\n",
    "print(df.head(), df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verif des dimensions X et Y\n",
      "      X (dataset sans la variable cible): (1337, 7)\n",
      "      Y (la variable cible) : (1337, 1)\n",
      " verif du split 80 20 \n",
      "80% du dataset : X train -> (1136, 7), Y train -> (1136, 1)\n",
      "20% du dataset : X test -> (201, 7), Y test -> (201, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet, LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, FunctionTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "\n",
    "# separation des features et de la variable cible\n",
    "X = df.drop('charges', axis=1)\n",
    "y = df[['charges']]\n",
    "print(f'''verif des dimensions X et Y\n",
    "      X (dataset sans la variable cible): {X.shape}\n",
    "      Y (la variable cible) : {y.shape}''')\n",
    "\n",
    "\n",
    "# division du dataset en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, train_size=0.85, random_state=42, stratify=X['smoker'])\n",
    "print(f''' verif du split 80 20 \n",
    "80% du dataset : X train -> {X_train.shape}, Y train -> {y_train.shape}\n",
    "20% du dataset : X test -> {X_test.shape}, Y test -> {y_test.shape}''')\n",
    "\n",
    "def log_transform(x):\n",
    "    return np.log(x + 1)\n",
    "\n",
    "log_transformer = FunctionTransformer(log_transform)\n",
    "\n",
    "preprocessor_num = Pipeline(steps=[\n",
    "    ('log', log_transformer),\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "preprocessor_cat = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder()),\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "])\n",
    "\n",
    "# preprocessing avec transformation des categories et des nums\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', preprocessor_num , ['age', 'bmi', 'children', 'bmi_smoker_interaction']),\n",
    "        ('cat', preprocessor_cat , ['region','sex', 'smoker']),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error du modèle dummy: 145320521.96584958\n",
      "Coefficient de determination R² du modèle dummy: -0.0027928862543942223\n",
      "Root Mean Squared Error (RMSE) du modèle dummy: 12054.89618229247\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# création du pipeline dummy\n",
    "pipeline_dummy = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', DummyRegressor(strategy='mean'))])\n",
    "\n",
    "\n",
    "# eviter data leakage -> entraîner le pipeline sur les données d'entraînement puis predire\n",
    "# sur l'ensemble de test avec le meme pipeline\n",
    "pipeline_dummy.fit(X_train, y_train)\n",
    "#puis predire y sur l'ensemble de test avec le meme pipeline\n",
    "y_pred = pipeline_dummy.predict(X_test)\n",
    "#print(y_pred_dummy)\n",
    "\n",
    "#test avec les differentes métriques pour le modele dummy : \n",
    "#comparaison du y prédit avec le y de test\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error du modèle dummy: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Coefficient de determination R² du modèle dummy: {r2}')\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE) du modèle dummy: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3061.88082114]\n",
      " [35171.76570092]\n",
      " [ 6871.41271491]\n",
      " [40277.57715372]\n",
      " [29215.22763672]\n",
      " [ 7054.31177625]\n",
      " [ 3669.73243318]\n",
      " [ 4711.61465566]\n",
      " [ 3434.92670354]\n",
      " [39500.12438196]\n",
      " [10553.84948957]\n",
      " [12827.58077833]\n",
      " [ 3669.01432013]\n",
      " [13089.02771045]\n",
      " [ 2896.28232717]\n",
      " [ 2612.98673315]\n",
      " [ 2347.86566414]\n",
      " [ 7029.61287321]\n",
      " [ 5210.47290723]\n",
      " [21071.00381976]\n",
      " [14783.36320812]\n",
      " [10459.96062719]\n",
      " [13949.54325772]\n",
      " [14638.73575417]\n",
      " [ 6273.72223521]\n",
      " [ 4862.956899  ]\n",
      " [12740.05257638]\n",
      " [11578.73486973]\n",
      " [ 3873.97423134]\n",
      " [ 2788.56730734]\n",
      " [ 4832.4118377 ]\n",
      " [13587.08947774]\n",
      " [11342.31914579]\n",
      " [20112.67247275]\n",
      " [29778.1139023 ]\n",
      " [49928.57839263]\n",
      " [ 5042.20702138]\n",
      " [13385.29912607]\n",
      " [16561.85638887]\n",
      " [11318.12899734]\n",
      " [ 6366.49040257]\n",
      " [ 6162.22586074]\n",
      " [26837.16324232]\n",
      " [14209.13942721]\n",
      " [31065.12054066]\n",
      " [ 3803.97129406]\n",
      " [11443.2502375 ]\n",
      " [12070.37939238]\n",
      " [43716.03059577]\n",
      " [11719.43753397]\n",
      " [ 5842.99842183]\n",
      " [41497.29836002]\n",
      " [15829.41031531]\n",
      " [14559.39949532]\n",
      " [ 3245.97287169]\n",
      " [15285.10516366]\n",
      " [ 7738.71994669]\n",
      " [ 9377.66797704]\n",
      " [ 9064.52113457]\n",
      " [ 5629.04644146]\n",
      " [ 3650.77074427]\n",
      " [41502.8200796 ]\n",
      " [12435.49944186]\n",
      " [10509.23703702]\n",
      " [15692.11140665]\n",
      " [12922.91064339]\n",
      " [ 4546.86979548]\n",
      " [12775.66984179]\n",
      " [ 6065.39981588]\n",
      " [ 6507.99124702]\n",
      " [ 6552.86281635]\n",
      " [ 9543.45483934]\n",
      " [32867.46020676]\n",
      " [ 8528.97330536]\n",
      " [40222.80292163]\n",
      " [ 6623.77377691]\n",
      " [ 4646.06099885]\n",
      " [13117.05760129]\n",
      " [12514.40551865]\n",
      " [31288.26870443]\n",
      " [ 3146.48745337]\n",
      " [ 3778.44146378]\n",
      " [ 9988.92717705]\n",
      " [26993.06591547]\n",
      " [11237.69844799]\n",
      " [36411.44204645]\n",
      " [10559.59460578]\n",
      " [ 4733.75502892]\n",
      " [13548.40308711]\n",
      " [13329.26074831]\n",
      " [ 9379.06993443]\n",
      " [27251.16198064]\n",
      " [12699.94968963]\n",
      " [ 9905.23312218]\n",
      " [ 4472.2127077 ]\n",
      " [ 2844.56547477]\n",
      " [ 5377.06670474]\n",
      " [ 5267.6794955 ]\n",
      " [ 8173.38372261]\n",
      " [11601.96047711]\n",
      " [ 5441.6968455 ]\n",
      " [ 6539.40090213]\n",
      " [ 3420.27560013]\n",
      " [ 4502.69278509]\n",
      " [ 2871.44574381]\n",
      " [33314.48531095]\n",
      " [ 5689.31845479]\n",
      " [12363.01924593]\n",
      " [ 3847.43101244]\n",
      " [11523.73693879]\n",
      " [14772.12685117]\n",
      " [ 5844.21124889]\n",
      " [10927.92907782]\n",
      " [10717.6553303 ]\n",
      " [11302.19498251]\n",
      " [10064.65340649]\n",
      " [ 7713.48805706]\n",
      " [ 5959.76194276]\n",
      " [12718.73393969]\n",
      " [16259.7950378 ]\n",
      " [14693.52314589]\n",
      " [10457.83081714]\n",
      " [ 3489.77193739]\n",
      " [24920.61161592]\n",
      " [27816.3974655 ]\n",
      " [12859.81865536]\n",
      " [10859.64109597]\n",
      " [ 7489.96615425]\n",
      " [10083.77547218]\n",
      " [40434.90877611]\n",
      " [ 7314.54466347]\n",
      " [ 6116.71445991]\n",
      " [ 4120.53251342]\n",
      " [ 2989.78212034]\n",
      " [ 3875.8505235 ]\n",
      " [ 8745.25560791]\n",
      " [14072.33415337]\n",
      " [ 6352.93182913]\n",
      " [10018.89352449]\n",
      " [ 5204.39356578]\n",
      " [ 6102.01408804]\n",
      " [12980.83734676]\n",
      " [ 8564.51478137]\n",
      " [10825.752296  ]\n",
      " [35997.13758849]\n",
      " [11582.73348994]\n",
      " [ 4804.26585282]\n",
      " [ 2384.1762505 ]\n",
      " [11206.68163463]\n",
      " [ 4557.71626062]\n",
      " [49100.39970346]\n",
      " [11648.33941237]\n",
      " [10880.67482271]\n",
      " [ 8133.68770227]\n",
      " [ 9851.54377689]\n",
      " [30756.64742972]\n",
      " [26624.3808293 ]\n",
      " [ 7339.9527135 ]\n",
      " [10979.22462374]\n",
      " [52351.4918774 ]\n",
      " [21816.62844944]\n",
      " [ 3904.48014516]\n",
      " [ 8002.06088671]\n",
      " [46970.12379787]\n",
      " [ 8115.40176596]\n",
      " [27214.43162065]\n",
      " [ 3553.60774962]\n",
      " [57083.46696231]\n",
      " [ 4971.65565489]\n",
      " [35459.70056217]\n",
      " [ 3791.36645591]\n",
      " [11200.98014353]\n",
      " [12492.7658258 ]\n",
      " [ 5509.42827973]\n",
      " [15503.56410872]\n",
      " [ 6841.44942597]\n",
      " [ 7213.81852986]\n",
      " [ 7613.85367429]\n",
      " [ 8709.17751866]\n",
      " [22104.71605103]\n",
      " [11257.85579392]\n",
      " [ 6143.95831393]\n",
      " [ 9691.86219097]\n",
      " [15538.86981724]\n",
      " [13960.68272655]\n",
      " [ 3120.51690862]\n",
      " [15391.85118589]\n",
      " [12063.85207056]\n",
      " [20005.53211779]\n",
      " [ 7222.98545759]\n",
      " [10854.77374992]\n",
      " [ 4576.1101676 ]\n",
      " [33644.04827235]\n",
      " [11276.22027545]\n",
      " [10595.7679317 ]\n",
      " [ 5460.54595349]\n",
      " [36919.48589883]\n",
      " [13286.30463064]\n",
      " [ 6081.21420575]\n",
      " [49135.53639193]\n",
      " [ 5803.33597972]]\n",
      "Mean Squared Error du modèle linear regression: 14375998.30852106\n",
      "Coefficient de determination R² du modèle linear regression: 0.9007975704905744\n",
      "Root Mean Squared Error (RMSE) du modèle linear regression: 3791.569372769152\n"
     ]
    }
   ],
   "source": [
    "# Modele de regression lineaire\n",
    "\n",
    "# création du pipeline de prétraitement et du modèle linear regression\n",
    "pipeline_lr = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regression', LinearRegression())])\n",
    "\n",
    "\n",
    "# entraîner le pipeline sur les données d'entraînement \n",
    "pipeline_lr.fit(X_train, y_train)\n",
    "#puis predire y sur l'ensemble de test avec le meme pipeline\n",
    "y_pred = pipeline_lr.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "#test des les differents metriques sur modele linear regression\n",
    "#comparaison du y prédit avec le y de test\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error du modèle linear regression: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Coefficient de determination R² du modèle linear regression: {r2}')\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE) du modèle linear regression: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13279.121486655948\n",
      "3791.569372769152\n"
     ]
    }
   ],
   "source": [
    "# Calculez le RMSE (la racine carrée du MSE) pour obtenir une idée de l'erreur en termes des unités d'origine de vos données. \n",
    "# Comparez le RMSE à la moyenne des 'charges' (df['charges'].mean()) pour évaluer l'erreur relative.\n",
    "\n",
    "# RMSE plus élevé que la moyenne : le modèle a du mal à capturer la variation et les tendances dans les données. \n",
    "# Il prédit généralement des valeurs qui sont relativement éloignées des valeurs réelles.\n",
    "\n",
    "# Erreur systématique :  le modèle a tendance à sous-estimer ou surestimer systématiquement les valeurs cibles.\n",
    "\n",
    "# Modèle insuffisamment performant : Un RMSE élevé peut également indiquer que le modèle que vous utilisez n'est pas suffisamment complexe \n",
    "# pour capturer les relations présentes dans les données. Cela peut signifier que le modèle ne tient pas compte de toutes les caractéristiques\n",
    "# pertinentes ou que la stratégie de prédiction choisie (comme la moyenne) n'est pas adaptée aux données.\n",
    "\n",
    "# En général, un bon modèle de régression devrait avoir un RMSE inférieur à la moyenne de la variable cible, \n",
    "# car cela indiquerait que le modèle est capable de faire des prédictions qui se rapprochent des valeurs réelles en moyenne. \n",
    "# L'objectif est de minimiser le RMSE pour obtenir des prédictions précises.\n",
    "\n",
    "print(df['charges'].mean())\n",
    "print(rmse)\n",
    "\n",
    "#donc on en résume que le modele dummy est tres mauvais, et c'est normal car le modele dummy \n",
    "#en général, le modèle dummy est un modèle très simple et naïf qui est utilisé comme baseline \n",
    "#pour évaluer la performance d'autres modèles plus sophistiqués."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donc on en résume que le modele dummy est tres mauvais, et c'est normal car le modele dummy <br>\n",
    "est un modèle très simple et naïf qui est utilisé comme baseline pour évaluer la performance d'autres modèles plus sophistiqués"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.046e+10, tolerance: 1.315e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.142e+10, tolerance: 1.298e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.162e+10, tolerance: 1.397e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.140e+10, tolerance: 1.381e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.759e+09, tolerance: 1.271e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.253e+09, tolerance: 1.315e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.015e+10, tolerance: 1.298e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e+10, tolerance: 1.397e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+10, tolerance: 1.381e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.682e+09, tolerance: 1.271e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.973e+09, tolerance: 1.315e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.457e+09, tolerance: 1.298e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.965e+09, tolerance: 1.397e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.116e+09, tolerance: 1.381e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.423e+09, tolerance: 1.271e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error du modèle lasso: 13963530.555437753\n",
      "Coefficient de determination R² du modèle lasso: 0.9036438286997107\n",
      "Root Mean Squared Error (RMSE) du modèle lasso: 3736.7807743347416 \n",
      " rappel moyenne charge : 13279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.218e+10, tolerance: 1.667e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# AVEC LE Modele de regression LASSO\n",
    "\n",
    "# création du pipeline de prétraitement et du modèle LASSO\n",
    "pipeline_lasso = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regression', Lasso())])\n",
    "\n",
    "#test de différents hyperparam d'alpha pour le lasso\n",
    "param_grid_lasso = {\n",
    "    'regression__alpha': [0.1, 1, 10, 100]  \n",
    "}\n",
    "\n",
    "### grid search\n",
    "grid_lasso = GridSearchCV(pipeline_lasso, param_grid_lasso, cv=5)\n",
    "\n",
    "\n",
    "# eviter data leakage -> entraîner le pipeline sur les données d'entraînement \n",
    "grid_lasso.fit(X_train, y_train)\n",
    "#puis predire y sur l'ensemble de test avec le meme pipeline\n",
    "y_pred = grid_lasso.predict(X_test)\n",
    "# print(y_pred)\n",
    "#test des les differents metriques sur modele lasso\n",
    "#comparaison du y prédit avec le y de test\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error du modèle lasso: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Coefficient de determination R² du modèle lasso: {r2}')\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE) du modèle lasso: {rmse} \\n rappel moyenne charge : 13279')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient de determination R² du modèle ridge: 0.9026759424286501\n",
      "Root Mean Squared Error (RMSE) du modèle ridge: 3755.501638627474 \n",
      " rappel moyenne charge : 13279\n"
     ]
    }
   ],
   "source": [
    "# Modele de regression RIDGE\n",
    "\n",
    "# création du pipeline de prétraitement et du modèle RIDGE\n",
    "pipeline_ridge = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regression', Ridge())])\n",
    "\n",
    "\n",
    "#test de différents hyperparam d'alpha pour le lasso\n",
    "param_grid_ridge = {\n",
    "    'regression__alpha': [0.01, 0.1, 1, 10, 100]  \n",
    "}\n",
    "\n",
    "### grid search\n",
    "grid_ridge = GridSearchCV(pipeline_ridge, param_grid_ridge, cv=5)\n",
    "\n",
    "\n",
    "# eviter data leakage -> entraîner le pipeline sur les données d'entraînement \n",
    "grid_ridge.fit(X_train, y_train)\n",
    "#puis predire y sur l'ensemble de test avec le meme pipeline\n",
    "y_pred = grid_ridge.predict(X_test)\n",
    "# print(y_pred)\n",
    "#test des les differents metriques sur modele lasso\n",
    "#comparaison du y prédit avec le y de test\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Coefficient de determination R² du modèle ridge: {r2}')\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE) du modèle ridge: {rmse} \\n rappel moyenne charge : 13279')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
