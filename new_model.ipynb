{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age     sex     bmi  children smoker     region      charges\n",
      "0   19  female  27.900         0    yes  southwest  16884.92400\n",
      "1   18    male  33.770         1     no  southeast   1725.55230\n",
      "2   28    male  33.000         3     no  southeast   4449.46200\n",
      "3   33    male  22.705         0     no  northwest  21984.47061\n",
      "4   32    male  28.880         0     no  northwest   3866.85520 (1337, 7)\n",
      "verif des dimensions X et Y\n",
      "      X (dataset sans la variable cible): (1337, 6)\n",
      "      Y (la variable cible) : (1337, 1)\n",
      " verif du split 80 20 \n",
      "80% du dataset : X train -> (1136, 6), Y train -> (1136, 1)\n",
      "# 20% du dataset : X test -> (201, 6), Y test -> (201, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures, FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet, LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "from joblib import dump \n",
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('dataset2.csv')\n",
    "\n",
    "print(df.head(), df.shape)\n",
    "# separation des features et de la variable cible\n",
    "X = df.drop('charges', axis=1)\n",
    "y = df[['charges']]\n",
    "print(f'''verif des dimensions X et Y\n",
    "      X (dataset sans la variable cible): {X.shape}\n",
    "      Y (la variable cible) : {y.shape}''')\n",
    "\n",
    "\n",
    "# division du dataset en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, train_size=0.85, random_state=42, stratify=X['smoker'])\n",
    "print(f''' verif du split 80 20 \n",
    "80% du dataset : X train -> {X_train.shape}, Y train -> {y_train.shape}\n",
    "# 20% du dataset : X test -> {X_test.shape}, Y test -> {y_test.shape}''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elasticnet\n",
    "# préprocesseur pour les variables numériques\n",
    "def log_transform(x):\n",
    "    return np.log(x + 1)\n",
    "\n",
    "log_transformer = FunctionTransformer(log_transform)\n",
    "\n",
    "preprocessor_num = Pipeline(steps=[\n",
    "    ('log', FunctionTransformer(log_transform)),\n",
    "    ('scaler', StandardScaler()) \n",
    "])\n",
    "\n",
    "preprocessor_cat = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', preprocessor_num, ['age', 'bmi', 'children']),\n",
    "        ('cat', preprocessor_cat, ['region', 'sex', 'smoker'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline_lasso = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('regression', Lasso())\n",
    "])\n",
    "\n",
    "#test de différents hyperparam d'alpha pour le lasso\n",
    "param_grid_lasso = {\n",
    "    'regression__alpha': np.arange(7,10,0.1),\n",
    "    'regression__precompute': [True],\n",
    "    'regression__max_iter': [5000],\n",
    "    \n",
    "}\n",
    "\n",
    "### grid search\n",
    "grid_lasso = GridSearchCV(pipeline_lasso, param_grid_lasso, cv=5)\n",
    "\n",
    "\n",
    "# eviter data leakage -> entraîner le pipeline sur les données d'entraînement \n",
    "grid_lasso.fit(X_train, y_train)\n",
    "#puis predire y sur l'ensemble de test avec le meme pipeline\n",
    "y_pred = grid_lasso.predict(X_test)\n",
    "# print(y_pred)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error du modèle elasticnet: 13890862.143149134\n",
      "Coefficient de determination R² du modèle elasticnet: 0.9041452813914066\n",
      "Root Mean Squared Error (RMSE) du modèle elasticnet: 3727.044692936903 \n",
      " rappel moyenne charge : 13279\n"
     ]
    }
   ],
   "source": [
    "#test des les differents metriques sur modele elasticnet\n",
    "#comparaison du y prédit avec le y de test\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error du modèle elasticnet: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Coefficient de determination R² du modèle elasticnet: {r2}')\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE) du modèle elasticnet: {rmse} \\n rappel moyenne charge : 13279')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PolynomialFeatures' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m coefficients\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Étape 2 : Gérer les transformations\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Pour PolynomialFeatures\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m poly_features \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamed_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpoly\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names\u001b[49m(input_features\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Pour OneHotEncoder\u001b[39;00m\n\u001b[1;32m     14\u001b[0m cat_features \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnamed_transformers_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoder\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget_feature_names(input_features\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregion\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmoker\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PolynomialFeatures' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "best_model = grid_lasso.best_estimator_\n",
    "\n",
    "# Extraire le modèle Lasso\n",
    "lasso_model = best_model.named_steps['regression']\n",
    "\n",
    "# Obtenir les coefficients\n",
    "coefficients = lasso_model.coef_\n",
    "coefficients\n",
    "\n",
    "# Étape 2 : Gérer les transformations\n",
    "# Pour PolynomialFeatures\n",
    "poly_features = best_model.named_steps['poly'].get_feature_names(input_features=X_train.columns)\n",
    "# Pour OneHotEncoder\n",
    "cat_features = best_model.named_steps['preprocessor'].named_transformers_['cat']['encoder'].get_feature_names(input_features=['region', 'sex', 'smoker'])\n",
    "# Combinez les noms de toutes les features\n",
    "all_features = np.concatenate([poly_features, cat_features])\n",
    "\n",
    "# Étape 3 : Associer les coefficients aux features\n",
    "feature_weights = dict(zip(all_features, coefficients))\n",
    "\n",
    "# Étape 4 : Afficher les poids\n",
    "sorted_weights = sorted(feature_weights.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "for feature, weight in sorted_weights:\n",
    "    print(f\"{feature}: {weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model.coeff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age     sex   bmi  children smoker     region  predicted_charges\n",
      "0   35  female  22.5         1    yes  southwest       17866.389731\n",
      "1   40    male  30.0         2     no  northeast        9389.059658\n",
      "2   30    male  25.0         0     no  southeast        4587.589497\n",
      "3   60  female  47.0         5    yes  southeast       58931.050406\n",
      "4   60  female  50.0         5    yes  southeast       61656.635909\n"
     ]
    }
   ],
   "source": [
    "new_data = pd.DataFrame({\n",
    "    'age': [35, 40, 30, 60,60],  \n",
    "    'sex': ['female', 'male', 'male', 'female','female'],  \n",
    "    'bmi': [22.5, 30.0, 25.0, 47,50],\n",
    "    'children': [1, 2, 0, 5,5],\n",
    "    'smoker': ['yes', 'no', 'no', 'yes','yes'],  \n",
    "    'region': ['southwest', 'northeast', 'southeast', 'southeast', 'southeast'],\n",
    "})\n",
    "\n",
    "# faire des prédictions avec le modèle optimisé\n",
    "new_y_ped = best_model.predict(new_data)\n",
    "\n",
    "# ajouter les prédictions à new_data\n",
    "new_data['predicted_charges'] = new_y_ped\n",
    "\n",
    "print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('best_model.pkl', 'wb') as fichier:\n",
    "    pickle.dump(best_model, fichier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
