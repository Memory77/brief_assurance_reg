{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age     sex     bmi  children smoker     region      charges\n",
      "0   19  female  27.900         0    yes  southwest  16884.92400\n",
      "1   18    male  33.770         1     no  southeast   1725.55230\n",
      "2   28    male  33.000         3     no  southeast   4449.46200\n",
      "3   33    male  22.705         0     no  northwest  21984.47061\n",
      "4   32    male  28.880         0     no  northwest   3866.85520 (1337, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('dataset2.csv')\n",
    "\n",
    "print(df.head(), df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verif des dimensions X et Y\n",
      "      X (dataset sans la variable cible): (1337, 6)\n",
      "      Y (la variable cible) : (1337, 1)\n",
      " verif du split 80 20 \n",
      "80% du dataset : X train -> (1136, 6), Y train -> (1136, 1)\n",
      "20% du dataset : X test -> (201, 6), Y test -> (201, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet, LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "\n",
    "# separation des features et de la variable cible\n",
    "X = df.drop('charges', axis=1)\n",
    "y = df[['charges']]\n",
    "print(f'''verif des dimensions X et Y\n",
    "      X (dataset sans la variable cible): {X.shape}\n",
    "      Y (la variable cible) : {y.shape}''')\n",
    "\n",
    "\n",
    "# division du dataset en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, train_size=0.85, random_state=42, stratify=X['smoker'])\n",
    "print(f''' verif du split 80 20 \n",
    "80% du dataset : X train -> {X_train.shape}, Y train -> {y_train.shape}\n",
    "20% du dataset : X test -> {X_test.shape}, Y test -> {y_test.shape}''')\n",
    "\n",
    "# preprocessing avec standardisation et transformation des categories\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['age', 'bmi', 'children']),\n",
    "        ('cat', OneHotEncoder(), ['region', 'sex', 'smoker'])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Mean Squared Error du modèle dummy: 145320521.96584958\n",
      "Coefficient de determination R² du modèle dummy: -0.0027928862543942223\n",
      "Root Mean Squared Error (RMSE) du modèle dummy: 12054.89618229247\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# création du pipeline dummy\n",
    "pipeline_dummy = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', DummyRegressor(strategy='mean'))])\n",
    "\n",
    "\n",
    "# eviter data leakage -> entraîner le pipeline sur les données d'entraînement puis predire\n",
    "# sur l'ensemble de test avec le meme pipeline\n",
    "pipeline_dummy.fit(X_train, y_train)\n",
    "#puis predire y sur l'ensemble de test avec le meme pipeline\n",
    "y_pred = pipeline_dummy.predict(X_test)\n",
    "#print(y_pred_dummy)\n",
    "score = pipeline_dummy.score(X_train, y_train)\n",
    "print(score)\n",
    "\n",
    "#test avec les differentes métriques pour le modele dummy : \n",
    "#comparaison du y prédit avec le y de test\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error du modèle dummy: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Coefficient de determination R² du modèle dummy: {r2}')\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE) du modèle dummy: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.00358847e+03]\n",
      " [ 3.22941049e+04]\n",
      " [ 7.71897135e+03]\n",
      " [ 3.54721454e+04]\n",
      " [ 2.69960861e+04]\n",
      " [ 7.55207298e+03]\n",
      " [ 1.96995795e+03]\n",
      " [ 4.17646602e+03]\n",
      " [ 9.58931378e+02]\n",
      " [ 3.32056593e+04]\n",
      " [ 1.13760146e+04]\n",
      " [ 1.34312613e+04]\n",
      " [-1.26217259e+02]\n",
      " [ 1.88731649e+04]\n",
      " [ 3.91507818e+01]\n",
      " [-1.11911436e+03]\n",
      " [ 1.97009979e+03]\n",
      " [ 6.05000691e+03]\n",
      " [ 1.50093688e+03]\n",
      " [ 3.11950973e+04]\n",
      " [ 1.29889330e+04]\n",
      " [ 9.09885174e+03]\n",
      " [ 1.10094393e+04]\n",
      " [ 1.40815681e+04]\n",
      " [ 7.32780772e+03]\n",
      " [ 1.86129570e+03]\n",
      " [ 1.17686815e+04]\n",
      " [ 1.06633380e+04]\n",
      " [ 4.15096975e+02]\n",
      " [ 4.82271858e+03]\n",
      " [ 3.33788710e+03]\n",
      " [ 1.24923449e+04]\n",
      " [ 9.93680616e+03]\n",
      " [ 2.89408348e+04]\n",
      " [ 2.98275561e+04]\n",
      " [ 3.85561052e+04]\n",
      " [ 2.33010667e+03]\n",
      " [ 1.19641286e+04]\n",
      " [ 1.94257224e+04]\n",
      " [ 9.33603026e+03]\n",
      " [ 7.13595553e+03]\n",
      " [ 5.76834904e+03]\n",
      " [ 3.38940335e+04]\n",
      " [ 2.69507633e+04]\n",
      " [ 3.54498543e+04]\n",
      " [ 3.18167465e+03]\n",
      " [ 1.31879443e+04]\n",
      " [ 1.07139916e+04]\n",
      " [ 2.96560850e+04]\n",
      " [ 1.14124392e+04]\n",
      " [ 5.58349476e+03]\n",
      " [ 3.72585636e+04]\n",
      " [ 1.55840027e+04]\n",
      " [ 1.38895959e+04]\n",
      " [ 3.25607008e+03]\n",
      " [ 1.56926508e+04]\n",
      " [ 7.69977251e+03]\n",
      " [ 8.61500346e+03]\n",
      " [ 9.73733106e+03]\n",
      " [ 4.28694983e+03]\n",
      " [ 1.99283358e+03]\n",
      " [ 3.70326547e+04]\n",
      " [ 1.18201764e+04]\n",
      " [ 1.04678653e+04]\n",
      " [ 1.36774933e+04]\n",
      " [ 2.70130964e+04]\n",
      " [ 2.61960793e+03]\n",
      " [ 1.39250081e+04]\n",
      " [ 2.01696029e+03]\n",
      " [ 6.75327878e+03]\n",
      " [ 5.33236342e+03]\n",
      " [ 9.81296785e+03]\n",
      " [ 3.68892024e+04]\n",
      " [ 1.05686676e+04]\n",
      " [ 3.91252461e+04]\n",
      " [ 6.77754734e+03]\n",
      " [ 2.35487580e+03]\n",
      " [ 9.93958610e+03]\n",
      " [ 1.05636834e+04]\n",
      " [ 3.36484402e+04]\n",
      " [ 1.51587586e+03]\n",
      " [ 2.68817786e+03]\n",
      " [ 8.84270018e+03]\n",
      " [ 3.30600327e+04]\n",
      " [ 9.48213268e+03]\n",
      " [ 3.23188494e+04]\n",
      " [ 9.75857963e+03]\n",
      " [ 6.25814516e+03]\n",
      " [ 1.25682067e+04]\n",
      " [ 1.07063146e+04]\n",
      " [ 7.18781525e+03]\n",
      " [ 3.52275832e+04]\n",
      " [ 1.44995144e+04]\n",
      " [ 8.61755526e+03]\n",
      " [ 4.85020760e+03]\n",
      " [ 8.51368692e+02]\n",
      " [ 8.42561151e+03]\n",
      " [ 1.88304104e+03]\n",
      " [ 1.25974977e+04]\n",
      " [ 1.12741707e+04]\n",
      " [ 3.39125318e+03]\n",
      " [ 8.33834494e+03]\n",
      " [ 4.97551398e+03]\n",
      " [ 6.53197505e+03]\n",
      " [-6.33169309e+02]\n",
      " [ 3.44104344e+04]\n",
      " [ 8.03431733e+03]\n",
      " [ 1.27603815e+04]\n",
      " [ 9.70433807e+02]\n",
      " [ 9.88150234e+03]\n",
      " [ 1.47927128e+04]\n",
      " [ 4.87148379e+03]\n",
      " [ 1.10146081e+04]\n",
      " [ 9.39781555e+03]\n",
      " [ 1.32589863e+04]\n",
      " [ 1.27260344e+04]\n",
      " [ 7.10985731e+03]\n",
      " [ 5.76306017e+03]\n",
      " [ 1.21283550e+04]\n",
      " [ 2.53372934e+04]\n",
      " [ 1.40759903e+04]\n",
      " [ 8.80903732e+03]\n",
      " [ 2.52642436e+03]\n",
      " [ 2.79766117e+04]\n",
      " [ 3.11622436e+04]\n",
      " [ 1.31567417e+04]\n",
      " [ 1.14253232e+04]\n",
      " [ 9.19009012e+03]\n",
      " [ 1.13265641e+04]\n",
      " [ 3.03201696e+04]\n",
      " [ 5.86744387e+03]\n",
      " [ 8.80245238e+03]\n",
      " [ 5.20967696e+03]\n",
      " [ 2.78762540e+02]\n",
      " [ 2.55908962e+03]\n",
      " [ 8.29799954e+03]\n",
      " [ 1.15186271e+04]\n",
      " [ 4.81914985e+03]\n",
      " [ 1.26625522e+04]\n",
      " [ 1.46909487e+03]\n",
      " [ 3.16178153e+03]\n",
      " [ 1.11750609e+04]\n",
      " [ 6.64457372e+03]\n",
      " [ 1.08161980e+04]\n",
      " [ 2.78494697e+04]\n",
      " [ 1.19951593e+04]\n",
      " [ 2.90315409e+03]\n",
      " [ 1.40029533e+03]\n",
      " [ 1.12803534e+04]\n",
      " [ 4.04130019e+03]\n",
      " [ 4.02174385e+04]\n",
      " [ 1.10801368e+04]\n",
      " [ 1.01365334e+04]\n",
      " [ 8.64766203e+03]\n",
      " [ 1.35024205e+04]\n",
      " [ 3.25287731e+04]\n",
      " [ 3.12938235e+04]\n",
      " [ 8.70540205e+03]\n",
      " [ 1.44803201e+04]\n",
      " [ 3.96383351e+04]\n",
      " [ 2.68878846e+04]\n",
      " [ 3.25758456e+03]\n",
      " [ 1.08338891e+04]\n",
      " [ 3.93474491e+04]\n",
      " [ 9.65593649e+03]\n",
      " [ 3.04329206e+04]\n",
      " [ 2.62895951e+02]\n",
      " [ 3.75092140e+04]\n",
      " [ 1.27932022e+03]\n",
      " [ 3.37440585e+04]\n",
      " [ 2.18227432e+03]\n",
      " [ 8.96397023e+03]\n",
      " [ 1.03667390e+04]\n",
      " [-1.45196986e+02]\n",
      " [ 1.23117617e+04]\n",
      " [ 1.16972297e+04]\n",
      " [ 7.82739337e+03]\n",
      " [ 5.29786076e+03]\n",
      " [ 9.24268073e+03]\n",
      " [ 3.07697734e+04]\n",
      " [ 1.51163612e+04]\n",
      " [ 4.08175585e+03]\n",
      " [ 1.49436674e+04]\n",
      " [ 1.81744319e+04]\n",
      " [ 1.36252021e+04]\n",
      " [ 4.02645963e+03]\n",
      " [ 1.32398483e+04]\n",
      " [ 1.11477228e+04]\n",
      " [ 3.30682696e+04]\n",
      " [ 4.73010901e+03]\n",
      " [ 1.04374208e+04]\n",
      " [ 3.68294457e+03]\n",
      " [ 3.20928715e+04]\n",
      " [ 1.61914162e+04]\n",
      " [ 1.01943124e+04]\n",
      " [ 3.50877747e+03]\n",
      " [ 3.72040539e+04]\n",
      " [ 1.32643623e+04]\n",
      " [ 6.41130311e+03]\n",
      " [ 3.34618431e+04]\n",
      " [ 3.77996187e+03]]\n",
      "0.7372497054902374\n",
      "Mean Squared Error du modèle linear regression: 25136492.83553787\n",
      "Coefficient de determination R² du modèle linear regression: 0.8265441393970117\n",
      "Root Mean Squared Error (RMSE) du modèle linear regression: 5013.630703944784\n"
     ]
    }
   ],
   "source": [
    "# Modele de regression lineaire\n",
    "\n",
    "# création du pipeline de prétraitement et du modèle linear regression\n",
    "pipeline_lr = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regression', LinearRegression())])\n",
    "\n",
    "\n",
    "# entraîner le pipeline sur les données d'entraînement \n",
    "pipeline_lr.fit(X_train, y_train)\n",
    "#puis predire y sur l'ensemble de test avec le meme pipeline\n",
    "y_pred = pipeline_lr.predict(X_test)\n",
    "print(y_pred)\n",
    "score = pipeline_lr.score(X_train, y_train)\n",
    "print(score)\n",
    "\n",
    "#test des les differents metriques sur modele linear regression\n",
    "#comparaison du y prédit avec le y de test\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error du modèle linear regression: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Coefficient de determination R² du modèle linear regression: {r2}')\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE) du modèle linear regression: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13279.121486655948\n",
      "5013.630703944784\n"
     ]
    }
   ],
   "source": [
    "# Calculez le RMSE (la racine carrée du MSE) pour obtenir une idée de l'erreur en termes des unités d'origine de vos données. \n",
    "# Comparez le RMSE à la moyenne des 'charges' (df['charges'].mean()) pour évaluer l'erreur relative.\n",
    "\n",
    "# RMSE plus élevé que la moyenne : le modèle a du mal à capturer la variation et les tendances dans les données. \n",
    "# Il prédit généralement des valeurs qui sont relativement éloignées des valeurs réelles.\n",
    "\n",
    "# Erreur systématique :  le modèle a tendance à sous-estimer ou surestimer systématiquement les valeurs cibles.\n",
    "\n",
    "# Modèle insuffisamment performant : Un RMSE élevé peut également indiquer que le modèle que vous utilisez n'est pas suffisamment complexe \n",
    "# pour capturer les relations présentes dans les données. Cela peut signifier que le modèle ne tient pas compte de toutes les caractéristiques\n",
    "# pertinentes ou que la stratégie de prédiction choisie (comme la moyenne) n'est pas adaptée aux données.\n",
    "\n",
    "# En général, un bon modèle de régression devrait avoir un RMSE inférieur à la moyenne de la variable cible, \n",
    "# car cela indiquerait que le modèle est capable de faire des prédictions qui se rapprochent des valeurs réelles en moyenne. \n",
    "# L'objectif est de minimiser le RMSE pour obtenir des prédictions précises.\n",
    "\n",
    "print(df['charges'].mean())\n",
    "print(rmse)\n",
    "\n",
    "#donc on en résume que le modele dummy est tres mauvais, et c'est normal car le modele dummy \n",
    "#en général, le modèle dummy est un modèle très simple et naïf qui est utilisé comme baseline \n",
    "#pour évaluer la performance d'autres modèles plus sophistiqués."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donc on en résume que le modele dummy est tres mauvais, et c'est normal car le modele dummy <br>\n",
    "est un modèle très simple et naïf qui est utilisé comme baseline pour évaluer la performance d'autres modèles plus sophistiqués"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7372494764548482\n",
      "Mean Squared Error du modèle lasso: 25130875.18607471\n",
      "Coefficient de determination R² du modèle lasso: 0.8265829043205263\n",
      "Root Mean Squared Error (RMSE) du modèle lasso: 5013.070434980414 \n",
      " rappel moyenne charge : 13279\n"
     ]
    }
   ],
   "source": [
    "# AVEC LE Modele de regression LASSO\n",
    "\n",
    "# création du pipeline de prétraitement et du modèle LASSO\n",
    "pipeline_lasso = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regression', Lasso())])\n",
    "\n",
    "#test de différents hyperparam d'alpha pour le lasso\n",
    "param_grid_lasso = {\n",
    "    'regression__alpha': [0.1, 1, 10, 100]  \n",
    "}\n",
    "\n",
    "### grid search\n",
    "grid_lasso = GridSearchCV(pipeline_lasso, param_grid_lasso, cv=5)\n",
    "\n",
    "\n",
    "# eviter data leakage -> entraîner le pipeline sur les données d'entraînement \n",
    "grid_lasso.fit(X_train, y_train)\n",
    "#puis predire y sur l'ensemble de test avec le meme pipeline\n",
    "y_pred = grid_lasso.predict(X_test)\n",
    "# print(y_pred)\n",
    "score = grid_lasso.score(X_train, y_train)\n",
    "print(score)\n",
    "#test des les differents metriques sur modele lasso\n",
    "#comparaison du y prédit avec le y de test\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error du modèle lasso: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Coefficient de determination R² du modèle lasso: {r2}')\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE) du modèle lasso: {rmse} \\n rappel moyenne charge : 13279')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7372448758641674\n",
      "Mean Squared Error du modèle ridge: 25136736.641929675\n",
      "Coefficient de determination R² du modèle ridge: 0.8265424569965356\n",
      "Root Mean Squared Error (RMSE) du modèle ridge: 5013.655018240653 \n",
      " rappel moyenne charge : 13279\n"
     ]
    }
   ],
   "source": [
    "# Modele de regression RIDGE\n",
    "\n",
    "# création du pipeline de prétraitement et du modèle RIDGE\n",
    "pipeline_ridge = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regression', Ridge())])\n",
    "\n",
    "\n",
    "#test de différents hyperparam d'alpha pour le lasso\n",
    "param_grid_ridge = {\n",
    "    'regression__alpha': [0.01, 0.1, 1, 10, 100]  \n",
    "}\n",
    "\n",
    "### grid search\n",
    "grid_ridge = GridSearchCV(pipeline_ridge, param_grid_ridge, cv=5)\n",
    "\n",
    "\n",
    "# eviter data leakage -> entraîner le pipeline sur les données d'entraînement \n",
    "grid_ridge.fit(X_train, y_train)\n",
    "#puis predire y sur l'ensemble de test avec le meme pipeline\n",
    "y_pred = grid_ridge.predict(X_test)\n",
    "# print(y_pred)\n",
    "score = grid_ridge.score(X_train, y_train)\n",
    "print(score)\n",
    "\n",
    "#test des les differents metriques sur modele lasso\n",
    "#comparaison du y prédit avec le y de test\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error du modèle ridge: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Coefficient de determination R² du modèle ridge: {r2}')\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE) du modèle ridge: {rmse} \\n rappel moyenne charge : 13279')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est plutot bien car on a un rmse plus bas que la moyenne pour le lasso et le ridge <br>\n",
    "l'objectif est de minimiser le RMSE pour obtenir des prédictions précises <br>\n",
    "r2 a 0,8 donc il predit la bonne réponse à 80% pour les deux modeles de regression <br>\n",
    "\n",
    "Les resultats des deux modeles de regression lasso et ridge sont presques les memes et ils sont netement mieux que le dummy modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 140 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n140 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/joblib/memory.py\", line 353, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py\", line 750, in fit_transform\n    self._validate_transformers()\n  File \"/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py\", line 430, in _validate_transformers\n    names, transformers, _ = zip(*self.transformers)\nValueError: not enough values to unpack (expected 3, got 2)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[316], line 40\u001b[0m\n\u001b[1;32m     36\u001b[0m grid_elasticnet \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline_elasticnet, param_grid_elasticnet, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# eviter data leakage -> entraîner le pipeline sur les données d'entraînement \u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[43mgrid_elasticnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#puis predire y sur l'ensemble de test avec le meme pipeline\u001b[39;00m\n\u001b[1;32m     42\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m grid_elasticnet\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/Bureau/ml/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Bureau/ml/lib/python3.10/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Bureau/ml/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Bureau/ml/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 875\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/Bureau/ml/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m     )\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 140 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n140 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/joblib/memory.py\", line 353, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py\", line 750, in fit_transform\n    self._validate_transformers()\n  File \"/home/utilisateur/Bureau/ml/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py\", line 430, in _validate_transformers\n    names, transformers, _ = zip(*self.transformers)\nValueError: not enough values to unpack (expected 3, got 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# Modele de regression Elasticnet\n",
    "# préprocesseur pour les variables numériques\n",
    "\n",
    "\n",
    "# preprocessor_cat = Pipeline(steps=[\n",
    "#     ('encoder', OneHotEncoder()),\n",
    "#     ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "# ])\n",
    "\n",
    "# preprocessor_num = Pipeline(steps=[\n",
    "#     ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "#     ('scaler', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# preprocessing avec transformation des categories et des nums\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['age', 'bmi', 'children']),\n",
    "        ('cat', OneHotEncoder(), ['region', 'sex', 'smoker']),\n",
    "        ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ]\n",
    ")\n",
    "# création du pipeline de prétraitement et du modèle elasticnet\n",
    "pipeline_elasticnet = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regression', ElasticNet())])\n",
    "\n",
    "\n",
    "#test de différents hyperparam d'alpha pour le lasso\n",
    "param_grid_elasticnet = {\n",
    "    'regression__alpha': [0.01, 0.1, 1, 10, 100, 200, 300],\n",
    "    'regression__l1_ratio' : [0.1, 0.5, 0.9, 1]\n",
    "}\n",
    "\n",
    "### grid search\n",
    "grid_elasticnet = GridSearchCV(pipeline_elasticnet, param_grid_elasticnet, cv=5)\n",
    "\n",
    "\n",
    "# eviter data leakage -> entraîner le pipeline sur les données d'entraînement \n",
    "grid_elasticnet.fit(X_train, y_train)\n",
    "#puis predire y sur l'ensemble de test avec le meme pipeline\n",
    "y_pred = grid_elasticnet.predict(X_test)\n",
    "# print(y_pred)\n",
    "\n",
    "\n",
    "#test des les differents metriques sur modele lasso\n",
    "#comparaison du y prédit avec le y de test\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error du modèle elasticnet: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Coefficient de determination R² du modèle elasticnet: {r2}')\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE) du modèle elasticnet: {rmse} \\n rappel moyenne charge : 13279')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;poly&#x27;,\n",
       "                                                                   PolynomialFeatures(include_bias=False)),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;age&#x27;, &#x27;bmi&#x27;, &#x27;children&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder()),\n",
       "                                                                  (&#x27;poly&#x27;,\n",
       "                                                                   PolynomialFeatures(include_bias=False))]),\n",
       "                                                  [&#x27;region&#x27;, &#x27;sex&#x27;,\n",
       "                                                   &#x27;smoker&#x27;])])),\n",
       "                (&#x27;regression&#x27;, ElasticNet(alpha=100, l1_ratio=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-140\" type=\"checkbox\" ><label for=\"sk-estimator-id-140\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;poly&#x27;,\n",
       "                                                                   PolynomialFeatures(include_bias=False)),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;age&#x27;, &#x27;bmi&#x27;, &#x27;children&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder()),\n",
       "                                                                  (&#x27;poly&#x27;,\n",
       "                                                                   PolynomialFeatures(include_bias=False))]),\n",
       "                                                  [&#x27;region&#x27;, &#x27;sex&#x27;,\n",
       "                                                   &#x27;smoker&#x27;])])),\n",
       "                (&#x27;regression&#x27;, ElasticNet(alpha=100, l1_ratio=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-141\" type=\"checkbox\" ><label for=\"sk-estimator-id-141\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;poly&#x27;,\n",
       "                                                  PolynomialFeatures(include_bias=False)),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;age&#x27;, &#x27;bmi&#x27;, &#x27;children&#x27;]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;encoder&#x27;, OneHotEncoder()),\n",
       "                                                 (&#x27;poly&#x27;,\n",
       "                                                  PolynomialFeatures(include_bias=False))]),\n",
       "                                 [&#x27;region&#x27;, &#x27;sex&#x27;, &#x27;smoker&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-142\" type=\"checkbox\" ><label for=\"sk-estimator-id-142\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;age&#x27;, &#x27;bmi&#x27;, &#x27;children&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-143\" type=\"checkbox\" ><label for=\"sk-estimator-id-143\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures(include_bias=False)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-144\" type=\"checkbox\" ><label for=\"sk-estimator-id-144\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-145\" type=\"checkbox\" ><label for=\"sk-estimator-id-145\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;region&#x27;, &#x27;sex&#x27;, &#x27;smoker&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-146\" type=\"checkbox\" ><label for=\"sk-estimator-id-146\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-147\" type=\"checkbox\" ><label for=\"sk-estimator-id-147\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures(include_bias=False)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-148\" type=\"checkbox\" ><label for=\"sk-estimator-id-148\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet(alpha=100, l1_ratio=1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('poly',\n",
       "                                                                   PolynomialFeatures(include_bias=False)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['age', 'bmi', 'children']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder()),\n",
       "                                                                  ('poly',\n",
       "                                                                   PolynomialFeatures(include_bias=False))]),\n",
       "                                                  ['region', 'sex',\n",
       "                                                   'smoker'])])),\n",
       "                ('regression', ElasticNet(alpha=100, l1_ratio=1))])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "best_model = grid_elasticnet.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age     sex   bmi  children smoker     region  predicted_charges\n",
      "0   35  female  22.5         1     no  southwest        4287.460994\n",
      "1   40    male  30.0         2    yes  northeast       31668.873424\n",
      "2   30  female  25.0         0     no  southeast        3104.492214\n",
      "3   60  female  47.0         5    yes  southeast       46598.302095\n",
      "4   60    male  50.0         5    yes  southeast       48567.057396\n"
     ]
    }
   ],
   "source": [
    "new_data = pd.DataFrame({\n",
    "    'age': [35, 40, 30, 60,60],  \n",
    "    'sex': ['female', 'male', 'female', 'female','male'],\n",
    "    'bmi': [22.5, 30.0, 25.0, 47,50],\n",
    "    'children': [1, 2, 0, 5,5],\n",
    "    'smoker': ['no', 'yes', 'no', 'yes','yes'],\n",
    "    'region': ['southwest', 'northeast', 'southeast', 'southeast', 'southeast']\n",
    "})\n",
    "\n",
    "# faire des prédictions avec le modèle optimisé, possible de faire best_model.predict aussi \n",
    "new_y_ped = grid_elasticnet.predict(new_data)\n",
    "\n",
    "# ajouter les prédictions à new_data\n",
    "new_data['predicted_charges'] = new_y_ped\n",
    "\n",
    "print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mElasticNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprecompute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcopy_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mselection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cyclic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Linear regression with combined L1 and L2 priors as regularizer.\n",
      "\n",
      "Minimizes the objective function::\n",
      "\n",
      "        1 / (2 * n_samples) * ||y - Xw||^2_2\n",
      "        + alpha * l1_ratio * ||w||_1\n",
      "        + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
      "\n",
      "If you are interested in controlling the L1 and L2 penalty\n",
      "separately, keep in mind that this is equivalent to::\n",
      "\n",
      "        a * ||w||_1 + 0.5 * b * ||w||_2^2\n",
      "\n",
      "where::\n",
      "\n",
      "        alpha = a + b and l1_ratio = a / (a + b)\n",
      "\n",
      "The parameter l1_ratio corresponds to alpha in the glmnet R package while\n",
      "alpha corresponds to the lambda parameter in glmnet. Specifically, l1_ratio\n",
      "= 1 is the lasso penalty. Currently, l1_ratio <= 0.01 is not reliable,\n",
      "unless you supply your own sequence of alpha.\n",
      "\n",
      "Read more in the :ref:`User Guide <elastic_net>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "alpha : float, default=1.0\n",
      "    Constant that multiplies the penalty terms. Defaults to 1.0.\n",
      "    See the notes for the exact mathematical meaning of this\n",
      "    parameter. ``alpha = 0`` is equivalent to an ordinary least square,\n",
      "    solved by the :class:`LinearRegression` object. For numerical\n",
      "    reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.\n",
      "    Given this, you should use the :class:`LinearRegression` object.\n",
      "\n",
      "l1_ratio : float, default=0.5\n",
      "    The ElasticNet mixing parameter, with ``0 <= l1_ratio <= 1``. For\n",
      "    ``l1_ratio = 0`` the penalty is an L2 penalty. ``For l1_ratio = 1`` it\n",
      "    is an L1 penalty.  For ``0 < l1_ratio < 1``, the penalty is a\n",
      "    combination of L1 and L2.\n",
      "\n",
      "fit_intercept : bool, default=True\n",
      "    Whether the intercept should be estimated or not. If ``False``, the\n",
      "    data is assumed to be already centered.\n",
      "\n",
      "precompute : bool or array-like of shape (n_features, n_features),                 default=False\n",
      "    Whether to use a precomputed Gram matrix to speed up\n",
      "    calculations. The Gram matrix can also be passed as argument.\n",
      "    For sparse input this option is always ``False`` to preserve sparsity.\n",
      "\n",
      "max_iter : int, default=1000\n",
      "    The maximum number of iterations.\n",
      "\n",
      "copy_X : bool, default=True\n",
      "    If ``True``, X will be copied; else, it may be overwritten.\n",
      "\n",
      "tol : float, default=1e-4\n",
      "    The tolerance for the optimization: if the updates are\n",
      "    smaller than ``tol``, the optimization code checks the\n",
      "    dual gap for optimality and continues until it is smaller\n",
      "    than ``tol``, see Notes below.\n",
      "\n",
      "warm_start : bool, default=False\n",
      "    When set to ``True``, reuse the solution of the previous call to fit as\n",
      "    initialization, otherwise, just erase the previous solution.\n",
      "    See :term:`the Glossary <warm_start>`.\n",
      "\n",
      "positive : bool, default=False\n",
      "    When set to ``True``, forces the coefficients to be positive.\n",
      "\n",
      "random_state : int, RandomState instance, default=None\n",
      "    The seed of the pseudo random number generator that selects a random\n",
      "    feature to update. Used when ``selection`` == 'random'.\n",
      "    Pass an int for reproducible output across multiple function calls.\n",
      "    See :term:`Glossary <random_state>`.\n",
      "\n",
      "selection : {'cyclic', 'random'}, default='cyclic'\n",
      "    If set to 'random', a random coefficient is updated every iteration\n",
      "    rather than looping over features sequentially by default. This\n",
      "    (setting to 'random') often leads to significantly faster convergence\n",
      "    especially when tol is higher than 1e-4.\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n",
      "    Parameter vector (w in the cost function formula).\n",
      "\n",
      "sparse_coef_ : sparse matrix of shape (n_features,) or             (n_targets, n_features)\n",
      "    Sparse representation of the `coef_`.\n",
      "\n",
      "intercept_ : float or ndarray of shape (n_targets,)\n",
      "    Independent term in decision function.\n",
      "\n",
      "n_iter_ : list of int\n",
      "    Number of iterations run by the coordinate descent solver to reach\n",
      "    the specified tolerance.\n",
      "\n",
      "dual_gap_ : float or ndarray of shape (n_targets,)\n",
      "    Given param alpha, the dual gaps at the end of the optimization,\n",
      "    same shape as each observation of y.\n",
      "\n",
      "n_features_in_ : int\n",
      "    Number of features seen during :term:`fit`.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "    Names of features seen during :term:`fit`. Defined only when `X`\n",
      "    has feature names that are all strings.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "See Also\n",
      "--------\n",
      "ElasticNetCV : Elastic net model with best model selection by\n",
      "    cross-validation.\n",
      "SGDRegressor : Implements elastic net regression with incremental training.\n",
      "SGDClassifier : Implements logistic regression with elastic net penalty\n",
      "    (``SGDClassifier(loss=\"log_loss\", penalty=\"elasticnet\")``).\n",
      "\n",
      "Notes\n",
      "-----\n",
      "To avoid unnecessary memory duplication the X argument of the fit method\n",
      "should be directly passed as a Fortran-contiguous numpy array.\n",
      "\n",
      "The precise stopping criteria based on `tol` are the following: First, check that\n",
      "that maximum coordinate update, i.e. :math:`\\max_j |w_j^{new} - w_j^{old}|`\n",
      "is smaller than `tol` times the maximum absolute coefficient, :math:`\\max_j |w_j|`.\n",
      "If so, then additionally check whether the dual gap is smaller than `tol` times\n",
      ":math:`||y||_2^2 / n_{      ext{samples}}`.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn.linear_model import ElasticNet\n",
      ">>> from sklearn.datasets import make_regression\n",
      "\n",
      ">>> X, y = make_regression(n_features=2, random_state=0)\n",
      ">>> regr = ElasticNet(random_state=0)\n",
      ">>> regr.fit(X, y)\n",
      "ElasticNet(random_state=0)\n",
      ">>> print(regr.coef_)\n",
      "[18.83816048 64.55968825]\n",
      ">>> print(regr.intercept_)\n",
      "1.451...\n",
      ">>> print(regr.predict([[0, 0]]))\n",
      "[1.451...]\n",
      "\u001b[0;31mFile:\u001b[0m           ~/Bureau/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py\n",
      "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[0;31mSubclasses:\u001b[0m     Lasso"
     ]
    }
   ],
   "source": [
    "ElasticNet?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
