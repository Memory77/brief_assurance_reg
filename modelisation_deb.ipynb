{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  sex     bmi  children  smoker     region      charges  \\\n",
      "0   19    1  27.900         0       1  southwest  16884.92400   \n",
      "1   18    0  33.770         1       0  southeast   1725.55230   \n",
      "2   28    0  33.000         3       0  southeast   4449.46200   \n",
      "3   33    0  22.705         0       0  northwest  21984.47061   \n",
      "4   32    0  28.880         0       0  northwest   3866.85520   \n",
      "\n",
      "   bmi_smoker_interaction  \n",
      "0                    27.9  \n",
      "1                     0.0  \n",
      "2                     0.0  \n",
      "3                     0.0  \n",
      "4                     0.0   (1337, 8)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('dataset3.csv')\n",
    "\n",
    "print(df.head(), df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verif des dimensions X et Y\n",
      "      X (dataset sans la variable cible): (1337, 7)\n",
      "      Y (la variable cible) : (1337, 1)\n",
      " verif du split 80 20 \n",
      "80% du dataset : X train -> (1136, 7), Y train -> (1136, 1)\n",
      "20% du dataset : X test -> (201, 7), Y test -> (201, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet, LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "\n",
    "# separation des features et de la variable cible\n",
    "X = df.drop('charges', axis=1)\n",
    "y = df[['charges']]\n",
    "print(f'''verif des dimensions X et Y\n",
    "      X (dataset sans la variable cible): {X.shape}\n",
    "      Y (la variable cible) : {y.shape}''')\n",
    "\n",
    "\n",
    "# division du dataset en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, train_size=0.85, random_state=42, stratify=X['smoker'])\n",
    "print(f''' verif du split 80 20 \n",
    "80% du dataset : X train -> {X_train.shape}, Y train -> {y_train.shape}\n",
    "20% du dataset : X test -> {X_test.shape}, Y test -> {y_test.shape}''')\n",
    "\n",
    "# preprocessing avec standardisation et transformation des categories\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['age', 'bmi', 'children']),\n",
    "        ('cat', OneHotEncoder(), ['region', 'sex', 'smoker'])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error du modèle dummy: 145320521.96584958\n",
      "Coefficient de determination R² du modèle dummy: -0.0027928862543942223\n",
      "Root Mean Squared Error (RMSE) du modèle dummy: 12054.89618229247\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# création du pipeline dummy\n",
    "pipeline_dummy = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', DummyRegressor(strategy='mean'))])\n",
    "\n",
    "\n",
    "# eviter data leakage -> entraîner le pipeline sur les données d'entraînement puis predire\n",
    "# sur l'ensemble de test avec le meme pipeline\n",
    "pipeline_dummy.fit(X_train, y_train)\n",
    "#puis predire y sur l'ensemble de test avec le meme pipeline\n",
    "y_pred = pipeline_dummy.predict(X_test)\n",
    "#print(y_pred_dummy)\n",
    "\n",
    "#test avec les differentes métriques pour le modele dummy : \n",
    "#comparaison du y prédit avec le y de test\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error du modèle dummy: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Coefficient de determination R² du modèle dummy: {r2}')\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE) du modèle dummy: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.00358847e+03]\n",
      " [ 3.22941049e+04]\n",
      " [ 7.71897135e+03]\n",
      " [ 3.54721454e+04]\n",
      " [ 2.69960861e+04]\n",
      " [ 7.55207298e+03]\n",
      " [ 1.96995795e+03]\n",
      " [ 4.17646602e+03]\n",
      " [ 9.58931378e+02]\n",
      " [ 3.32056593e+04]\n",
      " [ 1.13760146e+04]\n",
      " [ 1.34312613e+04]\n",
      " [-1.26217259e+02]\n",
      " [ 1.88731649e+04]\n",
      " [ 3.91507818e+01]\n",
      " [-1.11911436e+03]\n",
      " [ 1.97009979e+03]\n",
      " [ 6.05000691e+03]\n",
      " [ 1.50093688e+03]\n",
      " [ 3.11950973e+04]\n",
      " [ 1.29889330e+04]\n",
      " [ 9.09885174e+03]\n",
      " [ 1.10094393e+04]\n",
      " [ 1.40815681e+04]\n",
      " [ 7.32780772e+03]\n",
      " [ 1.86129570e+03]\n",
      " [ 1.17686815e+04]\n",
      " [ 1.06633380e+04]\n",
      " [ 4.15096975e+02]\n",
      " [ 4.82271858e+03]\n",
      " [ 3.33788710e+03]\n",
      " [ 1.24923449e+04]\n",
      " [ 9.93680616e+03]\n",
      " [ 2.89408348e+04]\n",
      " [ 2.98275561e+04]\n",
      " [ 3.85561052e+04]\n",
      " [ 2.33010667e+03]\n",
      " [ 1.19641286e+04]\n",
      " [ 1.94257224e+04]\n",
      " [ 9.33603026e+03]\n",
      " [ 7.13595553e+03]\n",
      " [ 5.76834904e+03]\n",
      " [ 3.38940335e+04]\n",
      " [ 2.69507633e+04]\n",
      " [ 3.54498543e+04]\n",
      " [ 3.18167465e+03]\n",
      " [ 1.31879443e+04]\n",
      " [ 1.07139916e+04]\n",
      " [ 2.96560850e+04]\n",
      " [ 1.14124392e+04]\n",
      " [ 5.58349476e+03]\n",
      " [ 3.72585636e+04]\n",
      " [ 1.55840027e+04]\n",
      " [ 1.38895959e+04]\n",
      " [ 3.25607008e+03]\n",
      " [ 1.56926508e+04]\n",
      " [ 7.69977251e+03]\n",
      " [ 8.61500346e+03]\n",
      " [ 9.73733106e+03]\n",
      " [ 4.28694983e+03]\n",
      " [ 1.99283358e+03]\n",
      " [ 3.70326547e+04]\n",
      " [ 1.18201764e+04]\n",
      " [ 1.04678653e+04]\n",
      " [ 1.36774933e+04]\n",
      " [ 2.70130964e+04]\n",
      " [ 2.61960793e+03]\n",
      " [ 1.39250081e+04]\n",
      " [ 2.01696029e+03]\n",
      " [ 6.75327878e+03]\n",
      " [ 5.33236342e+03]\n",
      " [ 9.81296785e+03]\n",
      " [ 3.68892024e+04]\n",
      " [ 1.05686676e+04]\n",
      " [ 3.91252461e+04]\n",
      " [ 6.77754734e+03]\n",
      " [ 2.35487580e+03]\n",
      " [ 9.93958610e+03]\n",
      " [ 1.05636834e+04]\n",
      " [ 3.36484402e+04]\n",
      " [ 1.51587586e+03]\n",
      " [ 2.68817786e+03]\n",
      " [ 8.84270018e+03]\n",
      " [ 3.30600327e+04]\n",
      " [ 9.48213268e+03]\n",
      " [ 3.23188494e+04]\n",
      " [ 9.75857963e+03]\n",
      " [ 6.25814516e+03]\n",
      " [ 1.25682067e+04]\n",
      " [ 1.07063146e+04]\n",
      " [ 7.18781525e+03]\n",
      " [ 3.52275832e+04]\n",
      " [ 1.44995144e+04]\n",
      " [ 8.61755526e+03]\n",
      " [ 4.85020760e+03]\n",
      " [ 8.51368692e+02]\n",
      " [ 8.42561151e+03]\n",
      " [ 1.88304104e+03]\n",
      " [ 1.25974977e+04]\n",
      " [ 1.12741707e+04]\n",
      " [ 3.39125318e+03]\n",
      " [ 8.33834494e+03]\n",
      " [ 4.97551398e+03]\n",
      " [ 6.53197505e+03]\n",
      " [-6.33169309e+02]\n",
      " [ 3.44104344e+04]\n",
      " [ 8.03431733e+03]\n",
      " [ 1.27603815e+04]\n",
      " [ 9.70433807e+02]\n",
      " [ 9.88150234e+03]\n",
      " [ 1.47927128e+04]\n",
      " [ 4.87148379e+03]\n",
      " [ 1.10146081e+04]\n",
      " [ 9.39781555e+03]\n",
      " [ 1.32589863e+04]\n",
      " [ 1.27260344e+04]\n",
      " [ 7.10985731e+03]\n",
      " [ 5.76306017e+03]\n",
      " [ 1.21283550e+04]\n",
      " [ 2.53372934e+04]\n",
      " [ 1.40759903e+04]\n",
      " [ 8.80903732e+03]\n",
      " [ 2.52642436e+03]\n",
      " [ 2.79766117e+04]\n",
      " [ 3.11622436e+04]\n",
      " [ 1.31567417e+04]\n",
      " [ 1.14253232e+04]\n",
      " [ 9.19009012e+03]\n",
      " [ 1.13265641e+04]\n",
      " [ 3.03201696e+04]\n",
      " [ 5.86744387e+03]\n",
      " [ 8.80245238e+03]\n",
      " [ 5.20967696e+03]\n",
      " [ 2.78762540e+02]\n",
      " [ 2.55908962e+03]\n",
      " [ 8.29799954e+03]\n",
      " [ 1.15186271e+04]\n",
      " [ 4.81914985e+03]\n",
      " [ 1.26625522e+04]\n",
      " [ 1.46909487e+03]\n",
      " [ 3.16178153e+03]\n",
      " [ 1.11750609e+04]\n",
      " [ 6.64457372e+03]\n",
      " [ 1.08161980e+04]\n",
      " [ 2.78494697e+04]\n",
      " [ 1.19951593e+04]\n",
      " [ 2.90315409e+03]\n",
      " [ 1.40029533e+03]\n",
      " [ 1.12803534e+04]\n",
      " [ 4.04130019e+03]\n",
      " [ 4.02174385e+04]\n",
      " [ 1.10801368e+04]\n",
      " [ 1.01365334e+04]\n",
      " [ 8.64766203e+03]\n",
      " [ 1.35024205e+04]\n",
      " [ 3.25287731e+04]\n",
      " [ 3.12938235e+04]\n",
      " [ 8.70540205e+03]\n",
      " [ 1.44803201e+04]\n",
      " [ 3.96383351e+04]\n",
      " [ 2.68878846e+04]\n",
      " [ 3.25758456e+03]\n",
      " [ 1.08338891e+04]\n",
      " [ 3.93474491e+04]\n",
      " [ 9.65593649e+03]\n",
      " [ 3.04329206e+04]\n",
      " [ 2.62895951e+02]\n",
      " [ 3.75092140e+04]\n",
      " [ 1.27932022e+03]\n",
      " [ 3.37440585e+04]\n",
      " [ 2.18227432e+03]\n",
      " [ 8.96397023e+03]\n",
      " [ 1.03667390e+04]\n",
      " [-1.45196986e+02]\n",
      " [ 1.23117617e+04]\n",
      " [ 1.16972297e+04]\n",
      " [ 7.82739337e+03]\n",
      " [ 5.29786076e+03]\n",
      " [ 9.24268073e+03]\n",
      " [ 3.07697734e+04]\n",
      " [ 1.51163612e+04]\n",
      " [ 4.08175585e+03]\n",
      " [ 1.49436674e+04]\n",
      " [ 1.81744319e+04]\n",
      " [ 1.36252021e+04]\n",
      " [ 4.02645963e+03]\n",
      " [ 1.32398483e+04]\n",
      " [ 1.11477228e+04]\n",
      " [ 3.30682696e+04]\n",
      " [ 4.73010901e+03]\n",
      " [ 1.04374208e+04]\n",
      " [ 3.68294457e+03]\n",
      " [ 3.20928715e+04]\n",
      " [ 1.61914162e+04]\n",
      " [ 1.01943124e+04]\n",
      " [ 3.50877747e+03]\n",
      " [ 3.72040539e+04]\n",
      " [ 1.32643623e+04]\n",
      " [ 6.41130311e+03]\n",
      " [ 3.34618431e+04]\n",
      " [ 3.77996187e+03]]\n",
      "Mean Squared Error du modèle linear regression: 25136492.835537862\n",
      "Coefficient de determination R² du modèle linear regression: 0.8265441393970117\n",
      "Root Mean Squared Error (RMSE) du modèle linear regression: 5013.630703944783\n"
     ]
    }
   ],
   "source": [
    "# Modele de regression lineaire\n",
    "\n",
    "# création du pipeline de prétraitement et du modèle linear regression\n",
    "pipeline_lr = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regression', LinearRegression())])\n",
    "\n",
    "\n",
    "# entraîner le pipeline sur les données d'entraînement \n",
    "pipeline_lr.fit(X_train, y_train)\n",
    "#puis predire y sur l'ensemble de test avec le meme pipeline\n",
    "y_pred = pipeline_lr.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "#test des les differents metriques sur modele linear regression\n",
    "#comparaison du y prédit avec le y de test\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error du modèle linear regression: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Coefficient de determination R² du modèle linear regression: {r2}')\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE) du modèle linear regression: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13279.121486655948\n",
      "5013.630703944783\n"
     ]
    }
   ],
   "source": [
    "# Calculez le RMSE (la racine carrée du MSE) pour obtenir une idée de l'erreur en termes des unités d'origine de vos données. \n",
    "# Comparez le RMSE à la moyenne des 'charges' (df['charges'].mean()) pour évaluer l'erreur relative.\n",
    "\n",
    "# RMSE plus élevé que la moyenne : le modèle a du mal à capturer la variation et les tendances dans les données. \n",
    "# Il prédit généralement des valeurs qui sont relativement éloignées des valeurs réelles.\n",
    "\n",
    "# Erreur systématique :  le modèle a tendance à sous-estimer ou surestimer systématiquement les valeurs cibles.\n",
    "\n",
    "# Modèle insuffisamment performant : Un RMSE élevé peut également indiquer que le modèle que vous utilisez n'est pas suffisamment complexe \n",
    "# pour capturer les relations présentes dans les données. Cela peut signifier que le modèle ne tient pas compte de toutes les caractéristiques\n",
    "# pertinentes ou que la stratégie de prédiction choisie (comme la moyenne) n'est pas adaptée aux données.\n",
    "\n",
    "# En général, un bon modèle de régression devrait avoir un RMSE inférieur à la moyenne de la variable cible, \n",
    "# car cela indiquerait que le modèle est capable de faire des prédictions qui se rapprochent des valeurs réelles en moyenne. \n",
    "# L'objectif est de minimiser le RMSE pour obtenir des prédictions précises.\n",
    "\n",
    "print(df['charges'].mean())\n",
    "print(rmse)\n",
    "\n",
    "#donc on en résume que le modele dummy est tres mauvais, et c'est normal car le modele dummy \n",
    "#en général, le modèle dummy est un modèle très simple et naïf qui est utilisé comme baseline \n",
    "#pour évaluer la performance d'autres modèles plus sophistiqués."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donc on en résume que le modele dummy est tres mauvais, et c'est normal car le modele dummy <br>\n",
    "est un modèle très simple et naïf qui est utilisé comme baseline pour évaluer la performance d'autres modèles plus sophistiqués"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error du modèle lasso: 25130875.18607471\n",
      "Coefficient de determination R² du modèle lasso: 0.8265829043205263\n",
      "Root Mean Squared Error (RMSE) du modèle lasso: 5013.070434980414 \n",
      " rappel moyenne charge : 13279\n"
     ]
    }
   ],
   "source": [
    "# AVEC LE Modele de regression LASSO\n",
    "\n",
    "# création du pipeline de prétraitement et du modèle LASSO\n",
    "pipeline_lasso = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regression', Lasso())])\n",
    "\n",
    "#test de différents hyperparam d'alpha pour le lasso\n",
    "param_grid_lasso = {\n",
    "    'regression__alpha': [0.1, 1, 10, 100]  \n",
    "}\n",
    "\n",
    "### grid search\n",
    "grid_lasso = GridSearchCV(pipeline_lasso, param_grid_lasso, cv=5)\n",
    "\n",
    "\n",
    "# eviter data leakage -> entraîner le pipeline sur les données d'entraînement \n",
    "grid_lasso.fit(X_train, y_train)\n",
    "#puis predire y sur l'ensemble de test avec le meme pipeline\n",
    "y_pred = grid_lasso.predict(X_test)\n",
    "# print(y_pred)\n",
    "#test des les differents metriques sur modele lasso\n",
    "#comparaison du y prédit avec le y de test\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error du modèle lasso: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Coefficient de determination R² du modèle lasso: {r2}')\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE) du modèle lasso: {rmse} \\n rappel moyenne charge : 13279')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error du modèle ridge: 25136736.641929675\n",
      "Coefficient de determination R² du modèle ridge: 0.8265424569965356\n",
      "Root Mean Squared Error (RMSE) du modèle ridge: 5013.655018240653 \n",
      " rappel moyenne charge : 13279\n"
     ]
    }
   ],
   "source": [
    "# Modele de regression RIDGE\n",
    "\n",
    "# création du pipeline de prétraitement et du modèle RIDGE\n",
    "pipeline_ridge = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regression', Ridge())])\n",
    "\n",
    "\n",
    "#test de différents hyperparam d'alpha pour le lasso\n",
    "param_grid_ridge = {\n",
    "    'regression__alpha': [0.01, 0.1, 1, 10, 100]  \n",
    "}\n",
    "\n",
    "### grid search\n",
    "grid_ridge = GridSearchCV(pipeline_ridge, param_grid_ridge, cv=5)\n",
    "\n",
    "\n",
    "# eviter data leakage -> entraîner le pipeline sur les données d'entraînement \n",
    "grid_ridge.fit(X_train, y_train)\n",
    "#puis predire y sur l'ensemble de test avec le meme pipeline\n",
    "y_pred = grid_ridge.predict(X_test)\n",
    "# print(y_pred)\n",
    "#test des les differents metriques sur modele lasso\n",
    "#comparaison du y prédit avec le y de test\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error du modèle ridge: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Coefficient de determination R² du modèle ridge: {r2}')\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE) du modèle ridge: {rmse} \\n rappel moyenne charge : 13279')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est plutot bien car on a un rmse plus bas que la moyenne pour le lasso et le ridge <br>\n",
    "l'objectif est de minimiser le RMSE pour obtenir des prédictions précises <br>\n",
    "r2 a 0,8 donc il predit la bonne réponse à 80% pour les deux modeles de regression <br>\n",
    "\n",
    "Les resultats des deux modeles de regression lasso et ridge sont presques les memes et ils sont netement mieux que le dummy modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.218e+10, tolerance: 1.518e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+10, tolerance: 1.465e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e+10, tolerance: 1.483e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e+10, tolerance: 1.483e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.275e+10, tolerance: 1.560e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.289e+10, tolerance: 1.504e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.277e+10, tolerance: 1.510e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.263e+10, tolerance: 1.541e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+10, tolerance: 1.455e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.161e+10, tolerance: 1.486e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.215e+10, tolerance: 1.518e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.218e+10, tolerance: 1.465e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.244e+10, tolerance: 1.483e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.289e+10, tolerance: 1.483e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e+10, tolerance: 1.560e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.285e+10, tolerance: 1.504e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e+10, tolerance: 1.510e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.260e+10, tolerance: 1.541e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.195e+10, tolerance: 1.455e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e+10, tolerance: 1.486e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.211e+10, tolerance: 1.518e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.214e+10, tolerance: 1.465e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.239e+10, tolerance: 1.483e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.285e+10, tolerance: 1.483e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.267e+10, tolerance: 1.560e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.281e+10, tolerance: 1.504e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.270e+10, tolerance: 1.510e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.256e+10, tolerance: 1.541e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.190e+10, tolerance: 1.455e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.157e+10, tolerance: 1.486e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.208e+10, tolerance: 1.518e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.212e+10, tolerance: 1.465e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e+10, tolerance: 1.483e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.282e+10, tolerance: 1.483e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.264e+10, tolerance: 1.560e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.278e+10, tolerance: 1.504e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.267e+10, tolerance: 1.510e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.253e+10, tolerance: 1.541e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.187e+10, tolerance: 1.455e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.155e+10, tolerance: 1.486e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.203e+10, tolerance: 1.518e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.208e+10, tolerance: 1.465e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.233e+10, tolerance: 1.483e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.277e+10, tolerance: 1.483e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.258e+10, tolerance: 1.560e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.273e+10, tolerance: 1.504e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e+10, tolerance: 1.510e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.248e+10, tolerance: 1.541e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.182e+10, tolerance: 1.455e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.152e+10, tolerance: 1.486e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.429e+09, tolerance: 1.518e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.464e+09, tolerance: 1.465e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.433e+09, tolerance: 1.483e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.436e+09, tolerance: 1.483e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.482e+09, tolerance: 1.560e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.520e+09, tolerance: 1.504e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e+09, tolerance: 1.510e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.554e+09, tolerance: 1.541e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.223e+09, tolerance: 1.455e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.072e+09, tolerance: 1.486e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+10, tolerance: 1.518e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.065e+10, tolerance: 1.465e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.082e+10, tolerance: 1.483e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e+10, tolerance: 1.483e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e+10, tolerance: 1.560e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.117e+10, tolerance: 1.504e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.104e+10, tolerance: 1.510e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e+10, tolerance: 1.541e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e+10, tolerance: 1.455e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.044e+10, tolerance: 1.486e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e+10, tolerance: 1.518e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.207e+10, tolerance: 1.465e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.230e+10, tolerance: 1.483e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e+10, tolerance: 1.483e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e+10, tolerance: 1.560e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.269e+10, tolerance: 1.504e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+10, tolerance: 1.510e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.246e+10, tolerance: 1.541e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.177e+10, tolerance: 1.455e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.152e+10, tolerance: 1.486e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error du modèle elasticnet: 14463007.288121333\n",
      "Coefficient de determination R² du modèle elasticnet: 0.9001971598630657\n",
      "Root Mean Squared Error (RMSE) du modèle elasticnet: 3803.0260698713773 \n",
      " rappel moyenne charge : 13279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.370e+10, tolerance: 1.667e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# Modele de regression Elasticnet\n",
    "# préprocesseur pour les variables numériques\n",
    "\n",
    "preprocessor_num = Pipeline(steps=[\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "preprocessor_cat = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder()),\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "])\n",
    "\n",
    "# preprocessing avec transformation des categories et des nums\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', preprocessor_num , ['age', 'bmi', 'children', 'bmi_smoker_interaction']),\n",
    "        ('cat', preprocessor_cat , ['region','sex', 'smoker']),\n",
    "    ]\n",
    ")\n",
    "# création du pipeline de prétraitement et du modèle elasticnet\n",
    "pipeline_elasticnet = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regression', ElasticNet())])\n",
    "\n",
    "\n",
    "#test de différents hyperparam d'alpha pour le lasso\n",
    "param_grid_elasticnet = {\n",
    "    'regression__alpha': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'regression__l1_ratio' : [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "### grid search\n",
    "grid_elasticnet = GridSearchCV(pipeline_elasticnet, param_grid_elasticnet, cv=10)\n",
    "\n",
    "\n",
    "# eviter data leakage -> entraîner le pipeline sur les données d'entraînement \n",
    "grid_elasticnet.fit(X_train, y_train)\n",
    "#puis predire y sur l'ensemble de test avec le meme pipeline\n",
    "y_pred = grid_elasticnet.predict(X_test)\n",
    "# print(y_pred)\n",
    "\n",
    "\n",
    "#test des les differents metriques sur modele lasso\n",
    "#comparaison du y prédit avec le y de test\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error du modèle elasticnet: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Coefficient de determination R² du modèle elasticnet: {r2}')\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE) du modèle elasticnet: {rmse} \\n rappel moyenne charge : 13279')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;poly&#x27;,\n",
       "                                                                   PolynomialFeatures(include_bias=False)),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;age&#x27;, &#x27;bmi&#x27;, &#x27;children&#x27;,\n",
       "                                                   &#x27;bmi_smoker_interaction&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder()),\n",
       "                                                                  (&#x27;poly&#x27;,\n",
       "                                                                   PolynomialFeatures(include_bias=False))]),\n",
       "                                                  [&#x27;region&#x27;, &#x27;sex&#x27;,\n",
       "                                                   &#x27;smoker&#x27;])])),\n",
       "                (&#x27;regression&#x27;, ElasticNet(alpha=0.001, l1_ratio=0.9))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;poly&#x27;,\n",
       "                                                                   PolynomialFeatures(include_bias=False)),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;age&#x27;, &#x27;bmi&#x27;, &#x27;children&#x27;,\n",
       "                                                   &#x27;bmi_smoker_interaction&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder()),\n",
       "                                                                  (&#x27;poly&#x27;,\n",
       "                                                                   PolynomialFeatures(include_bias=False))]),\n",
       "                                                  [&#x27;region&#x27;, &#x27;sex&#x27;,\n",
       "                                                   &#x27;smoker&#x27;])])),\n",
       "                (&#x27;regression&#x27;, ElasticNet(alpha=0.001, l1_ratio=0.9))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;poly&#x27;,\n",
       "                                                  PolynomialFeatures(include_bias=False)),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;age&#x27;, &#x27;bmi&#x27;, &#x27;children&#x27;,\n",
       "                                  &#x27;bmi_smoker_interaction&#x27;]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;encoder&#x27;, OneHotEncoder()),\n",
       "                                                 (&#x27;poly&#x27;,\n",
       "                                                  PolynomialFeatures(include_bias=False))]),\n",
       "                                 [&#x27;region&#x27;, &#x27;sex&#x27;, &#x27;smoker&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;age&#x27;, &#x27;bmi&#x27;, &#x27;children&#x27;, &#x27;bmi_smoker_interaction&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures(include_bias=False)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;region&#x27;, &#x27;sex&#x27;, &#x27;smoker&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures(include_bias=False)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet(alpha=0.001, l1_ratio=0.9)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('poly',\n",
       "                                                                   PolynomialFeatures(include_bias=False)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['age', 'bmi', 'children',\n",
       "                                                   'bmi_smoker_interaction']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder()),\n",
       "                                                                  ('poly',\n",
       "                                                                   PolynomialFeatures(include_bias=False))]),\n",
       "                                                  ['region', 'sex',\n",
       "                                                   'smoker'])])),\n",
       "                ('regression', ElasticNet(alpha=0.001, l1_ratio=0.9))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "best_model = grid_elasticnet.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  sex   bmi  children  smoker     region  bmi_smoker_interaction  \\\n",
      "0   35    1  22.5         1       1  southwest                    22.5   \n",
      "1   40    0  30.0         2       0  northeast                     0.0   \n",
      "2   30    0  25.0         0       0  southeast                     0.0   \n",
      "3   60    1  47.0         5       1  southeast                    47.0   \n",
      "4   60    1  50.0         5       1  southeast                    50.0   \n",
      "\n",
      "   predicted_charges  \n",
      "0       18585.070581  \n",
      "1        9507.420379  \n",
      "2        4348.075543  \n",
      "3       60160.369705  \n",
      "4       63526.018630  \n"
     ]
    }
   ],
   "source": [
    "new_data = pd.DataFrame({\n",
    "    'age': [35, 40, 30, 60,60],  \n",
    "    'sex': [1, 0, 0, 1,1],  \n",
    "    'bmi': [22.5, 30.0, 25.0, 47,50],\n",
    "    'children': [1, 2, 0, 5,5],\n",
    "    'smoker': [1, 0, 0, 1,1],  \n",
    "    'region': ['southwest', 'northeast', 'southeast', 'southeast', 'southeast'],\n",
    "    'bmi_smoker_interaction': [22.5,0,0,47,50]\n",
    "})\n",
    "\n",
    "# faire des prédictions avec le modèle optimisé, possible de faire best_model.predict aussi \n",
    "new_y_ped = grid_elasticnet.predict(new_data)\n",
    "\n",
    "# ajouter les prédictions à new_data\n",
    "new_data['predicted_charges'] = new_y_ped\n",
    "\n",
    "print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mElasticNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprecompute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcopy_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mselection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cyclic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Linear regression with combined L1 and L2 priors as regularizer.\n",
      "\n",
      "Minimizes the objective function::\n",
      "\n",
      "        1 / (2 * n_samples) * ||y - Xw||^2_2\n",
      "        + alpha * l1_ratio * ||w||_1\n",
      "        + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
      "\n",
      "If you are interested in controlling the L1 and L2 penalty\n",
      "separately, keep in mind that this is equivalent to::\n",
      "\n",
      "        a * ||w||_1 + 0.5 * b * ||w||_2^2\n",
      "\n",
      "where::\n",
      "\n",
      "        alpha = a + b and l1_ratio = a / (a + b)\n",
      "\n",
      "The parameter l1_ratio corresponds to alpha in the glmnet R package while\n",
      "alpha corresponds to the lambda parameter in glmnet. Specifically, l1_ratio\n",
      "= 1 is the lasso penalty. Currently, l1_ratio <= 0.01 is not reliable,\n",
      "unless you supply your own sequence of alpha.\n",
      "\n",
      "Read more in the :ref:`User Guide <elastic_net>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "alpha : float, default=1.0\n",
      "    Constant that multiplies the penalty terms. Defaults to 1.0.\n",
      "    See the notes for the exact mathematical meaning of this\n",
      "    parameter. ``alpha = 0`` is equivalent to an ordinary least square,\n",
      "    solved by the :class:`LinearRegression` object. For numerical\n",
      "    reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.\n",
      "    Given this, you should use the :class:`LinearRegression` object.\n",
      "\n",
      "l1_ratio : float, default=0.5\n",
      "    The ElasticNet mixing parameter, with ``0 <= l1_ratio <= 1``. For\n",
      "    ``l1_ratio = 0`` the penalty is an L2 penalty. ``For l1_ratio = 1`` it\n",
      "    is an L1 penalty.  For ``0 < l1_ratio < 1``, the penalty is a\n",
      "    combination of L1 and L2.\n",
      "\n",
      "fit_intercept : bool, default=True\n",
      "    Whether the intercept should be estimated or not. If ``False``, the\n",
      "    data is assumed to be already centered.\n",
      "\n",
      "precompute : bool or array-like of shape (n_features, n_features),                 default=False\n",
      "    Whether to use a precomputed Gram matrix to speed up\n",
      "    calculations. The Gram matrix can also be passed as argument.\n",
      "    For sparse input this option is always ``False`` to preserve sparsity.\n",
      "\n",
      "max_iter : int, default=1000\n",
      "    The maximum number of iterations.\n",
      "\n",
      "copy_X : bool, default=True\n",
      "    If ``True``, X will be copied; else, it may be overwritten.\n",
      "\n",
      "tol : float, default=1e-4\n",
      "    The tolerance for the optimization: if the updates are\n",
      "    smaller than ``tol``, the optimization code checks the\n",
      "    dual gap for optimality and continues until it is smaller\n",
      "    than ``tol``, see Notes below.\n",
      "\n",
      "warm_start : bool, default=False\n",
      "    When set to ``True``, reuse the solution of the previous call to fit as\n",
      "    initialization, otherwise, just erase the previous solution.\n",
      "    See :term:`the Glossary <warm_start>`.\n",
      "\n",
      "positive : bool, default=False\n",
      "    When set to ``True``, forces the coefficients to be positive.\n",
      "\n",
      "random_state : int, RandomState instance, default=None\n",
      "    The seed of the pseudo random number generator that selects a random\n",
      "    feature to update. Used when ``selection`` == 'random'.\n",
      "    Pass an int for reproducible output across multiple function calls.\n",
      "    See :term:`Glossary <random_state>`.\n",
      "\n",
      "selection : {'cyclic', 'random'}, default='cyclic'\n",
      "    If set to 'random', a random coefficient is updated every iteration\n",
      "    rather than looping over features sequentially by default. This\n",
      "    (setting to 'random') often leads to significantly faster convergence\n",
      "    especially when tol is higher than 1e-4.\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n",
      "    Parameter vector (w in the cost function formula).\n",
      "\n",
      "sparse_coef_ : sparse matrix of shape (n_features,) or             (n_targets, n_features)\n",
      "    Sparse representation of the `coef_`.\n",
      "\n",
      "intercept_ : float or ndarray of shape (n_targets,)\n",
      "    Independent term in decision function.\n",
      "\n",
      "n_iter_ : list of int\n",
      "    Number of iterations run by the coordinate descent solver to reach\n",
      "    the specified tolerance.\n",
      "\n",
      "dual_gap_ : float or ndarray of shape (n_targets,)\n",
      "    Given param alpha, the dual gaps at the end of the optimization,\n",
      "    same shape as each observation of y.\n",
      "\n",
      "n_features_in_ : int\n",
      "    Number of features seen during :term:`fit`.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "    Names of features seen during :term:`fit`. Defined only when `X`\n",
      "    has feature names that are all strings.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "See Also\n",
      "--------\n",
      "ElasticNetCV : Elastic net model with best model selection by\n",
      "    cross-validation.\n",
      "SGDRegressor : Implements elastic net regression with incremental training.\n",
      "SGDClassifier : Implements logistic regression with elastic net penalty\n",
      "    (``SGDClassifier(loss=\"log_loss\", penalty=\"elasticnet\")``).\n",
      "\n",
      "Notes\n",
      "-----\n",
      "To avoid unnecessary memory duplication the X argument of the fit method\n",
      "should be directly passed as a Fortran-contiguous numpy array.\n",
      "\n",
      "The precise stopping criteria based on `tol` are the following: First, check that\n",
      "that maximum coordinate update, i.e. :math:`\\max_j |w_j^{new} - w_j^{old}|`\n",
      "is smaller than `tol` times the maximum absolute coefficient, :math:`\\max_j |w_j|`.\n",
      "If so, then additionally check whether the dual gap is smaller than `tol` times\n",
      ":math:`||y||_2^2 / n_{      ext{samples}}`.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn.linear_model import ElasticNet\n",
      ">>> from sklearn.datasets import make_regression\n",
      "\n",
      ">>> X, y = make_regression(n_features=2, random_state=0)\n",
      ">>> regr = ElasticNet(random_state=0)\n",
      ">>> regr.fit(X, y)\n",
      "ElasticNet(random_state=0)\n",
      ">>> print(regr.coef_)\n",
      "[18.83816048 64.55968825]\n",
      ">>> print(regr.intercept_)\n",
      "1.451...\n",
      ">>> print(regr.predict([[0, 0]]))\n",
      "[1.451...]\n",
      "\u001b[0;31mFile:\u001b[0m           ~/Bureau/ML lib/ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py\n",
      "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[0;31mSubclasses:\u001b[0m     Lasso"
     ]
    }
   ],
   "source": [
    "ElasticNet?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
