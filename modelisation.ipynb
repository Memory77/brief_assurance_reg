{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age     sex     bmi  children smoker     region      charges\n",
      "0   19  female  27.900         0    yes  southwest  16884.92400\n",
      "1   18    male  33.770         1     no  southeast   1725.55230\n",
      "2   28    male  33.000         3     no  southeast   4449.46200\n",
      "3   33    male  22.705         0     no  northwest  21984.47061\n",
      "4   32    male  28.880         0     no  northwest   3866.85520 (1337, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('dataset2.csv')\n",
    "\n",
    "print(df.head(), df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verif des dimensions X et Y\n",
      "      X (dataset sans la variable cible): (1337, 6)\n",
      "      Y (la variable cible) : (1337,)\n",
      " verif du split 80 20 \n",
      "80% du dataset : X train -> (1069, 6), Y train -> (1069,)\n",
      "20% du dataset : X test -> (268, 6), Y test -> (268,)\n"
     ]
    }
   ],
   "source": [
    "# Dummy modele\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import math\n",
    "\n",
    "# separation des features et de la variable cible\n",
    "X = df.drop('charges', axis=1)\n",
    "Y = df['charges']\n",
    "print(f'''verif des dimensions X et Y\n",
    "      X (dataset sans la variable cible): {X.shape}\n",
    "      Y (la variable cible) : {Y.shape}''')\n",
    "\n",
    "# Y_log = np.log1p(Y)\n",
    "\n",
    "# division du dataset en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "print(f''' verif du split 80 20 \n",
    "80% du dataset : X train -> {X_train.shape}, Y train -> {y_train.shape}\n",
    "20% du dataset : X test -> {X_test.shape}, Y test -> {y_test.shape}''')\n",
    "\n",
    "# # Pipeline pour appliquer les transformations en séquence\n",
    "# num_pipeline = Pipeline([\n",
    "#     ('log', FunctionTransformer(np.log1p, validate=True)),\n",
    "#     ('scaler', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# Preprocessing avec ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['age', 'bmi', 'children']),\n",
    "        ('cat', OneHotEncoder(), ['region', 'sex', 'smoker'])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error du modèle dummy: 185298141.68739662\n",
      "Coefficient of Determination R² du modèle dummy: -0.008391982350864469\n",
      "Root Mean Squared Error (RMSE) du modèle dummy: 13612.426003009037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# création du pipeline dummy\n",
    "pipeline_dummy = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', DummyRegressor(strategy='mean'))])\n",
    "\n",
    "\n",
    "# eviter data leakage -> entraîner le pipeline sur les données d'entraînement puis predire\n",
    "# sur l'ensemble de test avec le meme pipeline\n",
    "pipeline_dummy.fit(X_train, y_train)\n",
    "#puis predire y sur l'ensemble de test avec le meme pipeline\n",
    "y_pred = pipeline_dummy.predict(X_test)\n",
    "#print(y_pred_dummy)\n",
    "\n",
    "\n",
    "#test avec les differentes métriques pour le modele dummy : \n",
    "#comparaison du y prédit avec le y de test\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error du modèle dummy: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Coefficient of Determination R² du modèle dummy: {r2}')\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE) du modèle dummy: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13279.121486655948\n",
      "13612.426003009037\n"
     ]
    }
   ],
   "source": [
    "# Calculez le RMSE (la racine carrée du MSE) pour obtenir une idée de l'erreur en termes des unités d'origine de vos données. \n",
    "# Comparez le RMSE à la moyenne des 'charges' (df['charges'].mean()) pour évaluer l'erreur relative.\n",
    "\n",
    "# RMSE plus élevé que la moyenne : le modèle a du mal à capturer la variation et les tendances dans les données. \n",
    "# Il prédit généralement des valeurs qui sont relativement éloignées des valeurs réelles.\n",
    "\n",
    "# Erreur systématique :  le modèle a tendance à sous-estimer ou surestimer systématiquement les valeurs cibles.\n",
    "\n",
    "# Modèle insuffisamment performant : Un RMSE élevé peut également indiquer que le modèle que vous utilisez n'est pas suffisamment complexe \n",
    "# pour capturer les relations présentes dans les données. Cela peut signifier que le modèle ne tient pas compte de toutes les caractéristiques\n",
    "# pertinentes ou que la stratégie de prédiction choisie (comme la moyenne) n'est pas adaptée aux données.\n",
    "\n",
    "# En général, un bon modèle de régression devrait avoir un RMSE inférieur à la moyenne de la variable cible, \n",
    "# car cela indiquerait que le modèle est capable de faire des prédictions qui se rapprochent des valeurs réelles en moyenne. \n",
    "# L'objectif est de minimiser le RMSE pour obtenir des prédictions précises.\n",
    "\n",
    "print(df['charges'].mean())\n",
    "print(rmse)\n",
    "\n",
    "#donc on en résume que le modele dummy est tres mauvais, et c'est normal car le modele dummy \n",
    "#en général, le modèle dummy est un modèle très simple et naïf qui est utilisé comme baseline \n",
    "#pour évaluer la performance d'autres modèles plus sophistiqués."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donc on en résume que le modele dummy est tres mauvais, et c'est normal car le modele dummy <br>\n",
    "est un modèle très simple et naïf qui est utilisé comme baseline pour évaluer la performance d'autres modèles plus sophistiqués"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7298809245190985\n",
      "Mean Squared Error du modèle lasso: 35640200.074576505\n",
      "Coefficient of Determination R² du modèle lasso: 0.8060461282703295\n",
      "Root Mean Squared Error (RMSE) du modèle lasso: 5969.941379492474\n"
     ]
    }
   ],
   "source": [
    "# AVEC LE Modele de regression LASSO\n",
    "\n",
    "\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# création du pipeline de prétraitement et du modèle dummy\n",
    "pipeline_lasso = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regression', Lasso())])\n",
    "\n",
    "\n",
    "#test de différents hyperparam d'alpha pour le lasso\n",
    "param_grid_lasso = {\n",
    "    'regression__alpha': [0.1, 1, 10, 100]  \n",
    "}\n",
    "\n",
    "### grid search\n",
    "grid_lasso = GridSearchCV(pipeline_lasso, param_grid_lasso, cv=5)\n",
    "\n",
    "\n",
    "# eviter data leakage -> entraîner le pipeline sur les données d'entraînement \n",
    "grid_lasso.fit(X_train, y_train)\n",
    "#puis predire y sur l'ensemble de test avec le meme pipeline\n",
    "y_pred = grid_lasso.predict(X_test)\n",
    "# print(y_pred)\n",
    "score = grid_lasso.score(X_train, y_train)\n",
    "print(score)\n",
    "#test des les differents metriques sur modele lasso\n",
    "#comparaison du y prédit avec le y de test\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error du modèle lasso: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Coefficient of Determination R² du modèle lasso: {r2}')\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE) du modèle lasso: {rmse}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13279.121486655948\n",
      "5969.941379492474\n"
     ]
    }
   ],
   "source": [
    "print(df['charges'].mean())\n",
    "print(rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error du modèle ridge: 35572594.477132455\n",
      "Coefficient of Determination R² du modèle ridge: 0.8064140377474771\n",
      "Root Mean Squared Error (RMSE) du modèle ridge: 5964.2765258774225\n"
     ]
    }
   ],
   "source": [
    "# Modele de regression RIDGE\n",
    "\n",
    "# création du pipeline de prétraitement et du modèle dummy\n",
    "pipeline_ridge = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regression', Ridge())])\n",
    "\n",
    "\n",
    "#test de différents hyperparam d'alpha pour le lasso\n",
    "param_grid_ridge = {\n",
    "    'regression__alpha': [0.01, 0.1, 1, 10, 100]  \n",
    "}\n",
    "\n",
    "### grid search\n",
    "grid_ridge = GridSearchCV(pipeline_ridge, param_grid_ridge, cv=5)\n",
    "\n",
    "\n",
    "# eviter data leakage -> entraîner le pipeline sur les données d'entraînement \n",
    "grid_ridge.fit(X_train, y_train)\n",
    "#puis predire y sur l'ensemble de test avec le meme pipeline\n",
    "y_pred = grid_ridge.predict(X_test)\n",
    "# print(y_pred)\n",
    "score = grid_ridge.score(X_train, y_train)\n",
    "print(score)\n",
    "\n",
    "#test des les differents metriques sur modele lasso\n",
    "#comparaison du y prédit avec le y de test\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error du modèle ridge: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Coefficient of Determination R² du modèle ridge: {r2}')\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE) du modèle ridge: {rmse}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13279.121486655948\n",
      "5964.2765258774225\n"
     ]
    }
   ],
   "source": [
    "print(df['charges'].mean())\n",
    "print(rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est plutot bien car on a un rmse plus bas que la moyenne pour le lasso et le ridge <br>\n",
    "l'objectif est de minimiser le RMSE pour obtenir des prédictions précises <br>\n",
    "r2 a 0,8 donc il predit la bonne réponse à 80% pour les deux modeles de regression <br>\n",
    "\n",
    "Les resultats des deux modeles de regression lasso et ridge sont presques les memes et ils sont netement mieux que le dummy modele"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
